{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d047ef",
   "metadata": {},
   "source": [
    "# 一 安装环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d406e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:51.290032Z",
     "start_time": "2025-07-26T03:24:51.286278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 执行代码\n",
    "# !uv init . --name \"shanghai_road_clustering_analysis\"\n",
    "# !uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817797",
   "metadata": {},
   "source": [
    "# 二 收集并且检查数据\n",
    "原始数据分为两个，解压获取。\n",
    "[道路数据：](data/SHP格式路网.7z)\n",
    "[省份与市区县的字典原始数据](data/省份与市区县的数据.7z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a68fb3",
   "metadata": {},
   "source": [
    "## 道路数据\n",
    "图简单用了网上下载的数据：https://mp.weixin.qq.com/s/TEOYs2PJwX4PaN6tKJ3udg\n",
    "> 说明：“本次分享上海市路网数据，包含SHP格式和“模型格式”。GCJ02坐标系，共363398条路段，累计36666公里。已经处理好拓扑关系和连通性，可导入ArcMap、TransCAD或SUMO等交通模型工具生成路网模型，用于路径规划和交通仿真。路网示意图见图1。”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20dfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:55.819599Z",
     "start_time": "2025-07-26T03:24:51.538961Z"
    }
   },
   "outputs": [],
   "source": [
    "# 检查现有的 `SH_LINK.shp` 数据质量\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "roads_gdf = gpd.read_file(r'data\\上海路网数据\\上海路网数据\\SHP格式路网\\SH_LINK.shp') \n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b955268b252dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:55.872899Z",
     "start_time": "2025-07-26T03:24:55.867755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 检查空间参考 显示是4326 因为我们做路网聚类，我就不去深究坐标系对不对了\n",
    "roads_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec3559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:56.023816Z",
     "start_time": "2025-07-26T03:24:56.007330Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预处理数据\n",
    "# 选取需要的字段\n",
    "roads_gdf = roads_gdf[['ROAD', 'geometry']]\n",
    "# 重命名字段\n",
    "roads_gdf.rename(columns={'ROAD': 'name'}, inplace=True)\n",
    "\n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ad1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找找南京西路\n",
    "roads_gdf.query(\"name == '南京西路'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删掉 name 为空的行\n",
    "roads_gdf = roads_gdf[roads_gdf['name'].notna()]\n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acc0ad",
   "metadata": {},
   "source": [
    "### 限定研究范围到上海市中心的几个区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd50614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 限定道路范围 只对上海中心城区进行匹配，这是1945年那场大规模路名改革的核心地带\n",
    "districts_gdf = gpd.read_file(r'data\\省份与市区县的数据\\分年龄、性别的人口_区县等级.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97088818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查空间参考\n",
    "districts_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_gdf = districts_gdf[districts_gdf['省级'] == '上海市'].copy()\n",
    "\n",
    "# 选择需要的字段\n",
    "districts_gdf = districts_gdf[['地名', 'geometry']].copy()\n",
    "\n",
    "CENTRAL_DISTRICTS = ['黄浦区', '徐汇区', '长宁区', '静安区', '普陀区', '虹口区', '杨浦区']\n",
    "\n",
    "# 过滤出中心城区\n",
    "central_districts_gdf = districts_gdf[districts_gdf[\"地名\"].isin(CENTRAL_DISTRICTS)]\n",
    "\n",
    "# 合并中心城区边界以创建研究范围 (A\n",
    "aoi_polygon = central_districts_gdf.union_all()\n",
    "\n",
    "aoi_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc703df",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_polygon_df = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=central_districts_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"data/shanghai_roads_merged.gpkg\"\n",
    "\n",
    "aoi_polygon_df.to_file(output_filename, layer='shanghai_selected_districts', driver=\"GPKG\", engine='fiona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用空间索引筛选位于研究范围内的道路\n",
    "roads_in_aoi_gdf = gpd.sjoin(roads_gdf, gpd.GeoDataFrame(geometry=[aoi_polygon], crs=central_districts_gdf.crs), how=\"inner\", predicate='intersects')\n",
    "# sjoin会添加一个'index_right'列，我们可以把它去掉\n",
    "roads_in_aoi_gdf = roads_in_aoi_gdf.drop(columns=['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d90a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_in_aoi_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59284d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_in_aoi_gdf.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf4dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:54:58.456437Z",
     "start_time": "2025-07-24T09:54:58.439576Z"
    }
   },
   "source": [
    "从OpenStreetMap等标准来源下载的路网数据，为了保证网络的拓扑关系（即，知道哪条路和哪条路是连通的），在每一个交叉口，路段（LineString）都必须被打断成独立的小段。如果我们为“南京西路”的每一小段都计算一个质心，那么在“南京西路”这条路上就会产生密密麻麻几十个点，这会给聚类分析带来巨大的噪声和权重偏差。也会产生可视化混乱。\n",
    "要解决这个问题，我们需要在分析流程中增加一个关键的数据预处理步骤——道路合并。\n",
    "\n",
    "### 道路合并\n",
    "这个操作的核心思想是：将所有拥有相同路名 (name 字段相同) 并且在空间上能够首尾相接的零散线段，合并成一个单一的、更长的几何对象（MultiLineString）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f9118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:58.374260Z",
     "start_time": "2025-07-26T03:24:56.112911Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用 Geopandas 的 Dissolve 功能\n",
    "# 我们告诉geopandas，按'name'字段进行分组。\n",
    "# 对于每个分组（即所有同名的路段），它会自动将它们的几何图形合并。\n",
    "# reset_index() 是为了将'name'从索引变回普通的列\n",
    "dissolved_roads_in_aoi = roads_in_aoi_gdf.dissolve(by='name').reset_index()\n",
    "dissolved_roads_in_aoi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273e603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:58.453045Z",
     "start_time": "2025-07-26T03:24:58.449010Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看道路合并前后的数据差距\n",
    "print(f\"原始数据行数: {len(roads_in_aoi_gdf)}\")\n",
    "print(f\"合并后数据行数: {len(dissolved_roads_in_aoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e96b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:00.474604Z",
     "start_time": "2025-07-26T03:24:58.624292Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理合并后的几何对象 尝试将 MultiLineString 合并为单一的 LineString\n",
    "from shapely.ops import linemerge, unary_union\n",
    "\n",
    "def merge_lines(geom):\n",
    "    \"\"\"\n",
    "    尝试将MultiLineString合并为单一LineString\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 检查几何类型\n",
    "        if geom.geom_type == 'LineString':\n",
    "            # 已经是LineString，直接返回\n",
    "            return geom\n",
    "        elif geom.geom_type == 'MultiLineString':\n",
    "            # 先使用unary_union清理几何对象，处理可能的重叠或自相交\n",
    "            cleaned_geom = unary_union(geom)\n",
    "            \n",
    "            # 尝试使用linemerge合并连接的线段\n",
    "            merged = linemerge(cleaned_geom)\n",
    "            \n",
    "            # linemerge可能返回LineString或MultiLineString\n",
    "            return merged\n",
    "        else:\n",
    "            # 其他几何类型，直接返回\n",
    "            return geom\n",
    "    except Exception as e:\n",
    "        print(f\"合并失败，保留原始几何: {e}\")\n",
    "        return geom\n",
    "\n",
    "# 应用合并函数前，先检查几何类型分布\n",
    "print(\"=== 合并前几何类型分布 ===\")\n",
    "geom_types = dissolved_roads_in_aoi['geometry'].apply(lambda x: x.geom_type).value_counts()\n",
    "print(geom_types)\n",
    "\n",
    "# 应用合并函数\n",
    "print(\"\\n正在处理几何合并...\")\n",
    "dissolved_roads_in_aoi['geometry'] = dissolved_roads_in_aoi['geometry'].apply(merge_lines)\n",
    "\n",
    "# 检查合并后的几何类型分布\n",
    "print(\"\\n=== 合并后几何类型分布 ===\")\n",
    "geom_types_after = dissolved_roads_in_aoi['geometry'].apply(lambda x: x.geom_type).value_counts()\n",
    "print(geom_types_after)\n",
    "\n",
    "print(\"✅ 几何合并处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab14f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:00.850626Z",
     "start_time": "2025-07-26T03:25:00.492542Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"✅ 道路合并处理完成！\")\n",
    "\n",
    "# --- 4. 保存结果 ---\n",
    "\n",
    "dissolved_roads_in_aoi.to_file(output_filename, layer='merged_roads_in_aoi', driver=\"GPKG\", engine='fiona') # 确保使用 'fiona' 引擎 不然用arcgispro打不开 bug？\n",
    "print(f\"✅ 合并后的路网数据已保存到 '{output_filename}'\")\n",
    "\n",
    "print(\"\\n📊 合并后数据预览:\")\n",
    "print(dissolved_roads_in_aoi[['name', 'geometry']].head().to_string())\n",
    "print(f\"\\n📈 数据统计:\")\n",
    "print(f\"原始道路数量: {len(roads_in_aoi_gdf)}\")\n",
    "print(f\"合并后道路数量: {len(dissolved_roads_in_aoi)}\")\n",
    "print(f\"数据压缩率: {(1 - len(dissolved_roads_in_aoi)/len(roads_in_aoi_gdf))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始路网我们融合之后也保存一份\n",
    "all_roads_gdf_dissolve = roads_gdf.dissolve(by='name').reset_index()\n",
    "all_roads_gdf_dissolve.to_file(output_filename, layer='all_shanghai_roads', driver=\"GPKG\", engine='fiona')\n",
    "print(f\"✅ 原始路网数据已保存到 '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1b5d0",
   "metadata": {},
   "source": [
    "## 构建地名词典\n",
    "从以往的省市县shp中提取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cc41ed47fc5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.155187Z",
     "start_time": "2025-07-26T03:25:00.874256Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf = gpd.read_file(r\"data\\省份与市区县的数据\\分年龄、性别的人口_区县等级.shp\")\n",
    "\n",
    "places_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb8ff20275c18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.207740Z",
     "start_time": "2025-07-26T03:25:01.203333Z"
    }
   },
   "outputs": [],
   "source": [
    "# 检查空间参考\n",
    "places_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8b5edc9964284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.458792Z",
     "start_time": "2025-07-26T03:25:01.453670Z"
    }
   },
   "outputs": [],
   "source": [
    "# 先切片再复制\n",
    "places_gdf = places_gdf[['地名', '省级', 'geometry']].copy()\n",
    "\n",
    "# 重命名字段\n",
    "places_gdf.rename(columns={'地名': 'place_name', '省级': 'province'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fd88e7ffa4b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.623566Z",
     "start_time": "2025-07-26T03:25:01.597176Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583f3dbf8cdbed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.692171Z",
     "start_time": "2025-07-26T03:25:01.674060Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "province_gdf = places_gdf[['province']].drop_duplicates().copy()\n",
    "\n",
    "# 剔除上海市\n",
    "province_gdf = province_gdf[province_gdf['province'] != '上海市'].copy()\n",
    "\n",
    "# 将省份本身也加入到地名总表中\n",
    "province_gdf['place_name'] = province_gdf['province']\n",
    "\n",
    "\n",
    "# 调整列顺序与原表一致\n",
    "province_gdf = province_gdf[['place_name', 'province']]\n",
    "\n",
    "# 合并省份和原有地名表\n",
    "places_gdf_all = pd.concat([places_gdf, province_gdf], ignore_index=True)\n",
    "\n",
    "places_gdf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933890014def1ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.919003Z",
     "start_time": "2025-07-26T03:25:01.908631Z"
    }
   },
   "outputs": [],
   "source": [
    "# 按省份分组 按place_name排序\n",
    "places_gdf_all.groupby('province')['place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa3655c7c37ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.158720Z",
     "start_time": "2025-07-26T03:25:02.152597Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最后一步清洗 为了方便匹配路名（南京路），需要把plance_name中的 省 自治区 市 地区去掉，而province不变\n",
    "def clean_place_name(name):\n",
    "    # 去掉省、市、自治区等后缀\n",
    "    suffixes = ['自治区', '自治州', '自治县', '地区', '省', '县', '区','市']\n",
    "    for suffix in suffixes:\n",
    "        if name.endswith(suffix):\n",
    "            return name[:-len(suffix)]\n",
    "    return name\n",
    "# 应用清洗函数\n",
    "places_gdf_all['cleaned_place_name'] = places_gdf_all['place_name'].apply(clean_place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee9d9730d170b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.412764Z",
     "start_time": "2025-07-26T03:25:02.403875Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf_all.groupby('province')['cleaned_place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6974a315c85eeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.525145Z",
     "start_time": "2025-07-26T03:25:02.519572Z"
    }
   },
   "outputs": [],
   "source": [
    "# 删除 province为不统计的 以及港澳台\n",
    "places_gdf_all = places_gdf_all[~places_gdf_all['province'].isin(['上海市', '港澳台', '澳门特别行政区', '香港特别行政区', '不统计', '台湾省'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf5e86b8d1c30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.718650Z",
     "start_time": "2025-07-26T03:25:02.707285Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf_all.groupby('province')['cleaned_place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72743fd443321707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.380646Z",
     "start_time": "2025-07-26T03:25:02.856470Z"
    }
   },
   "outputs": [],
   "source": [
    "# 可选 保存数据\n",
    "places_gdf_all.to_file(output_filename, layer='province_and_places', driver=\"GPKG\", engine='fiona')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c3ce40a8626bb",
   "metadata": {},
   "source": [
    "## 三 开始匹配\n",
    "思考：\n",
    "1. 地名来源多样性：路名核心词既可能是城市，也可能是省份。例如“南京路”对应城市，“西藏中路”则直接对应省份。\n",
    "2. 后缀词汇丰富: 不仅仅是“路”，还有“道”、“街”、“巷”、“弄”、“浜”、“桥”等等，一个固定的后缀列表很难做到完全覆盖。\n",
    "3. 前后缀并存：“陕西南路”有前缀“南”和后缀“路”；“东宝兴路”的“东”是方位词；这都增加了提取核心词的难度。\n",
    "核心解決措施：不尝试去“猜”和“剥离”路名的前后缀。相反，我们拿着一个权威的、包含所有可能地名（城市+省份）的“字典” ，去路名这个“长字符串”里，寻找最长、最优先的匹配子串。\n",
    "所以我叫：**基于优先级的最大子串匹配**，为此还需要重新处理地名表 places_gdf_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b260d387de6cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.464183Z",
     "start_time": "2025-07-26T03:25:04.458376Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算地名长度，并按长度降序排列 后续先匹配地名长的\n",
    "# 因为总表是按长度降序的，所以第一个找到的匹配项，必然是这条路名中可能存在的最长地名。例如，对于“陕西南路”，它会先尝试匹配“陕西”，一旦成功，就立即返回“陕西”，绝不会有机会去匹配更短的“陕”。\n",
    "\n",
    "places_gdf_all['name_len'] = places_gdf_all['cleaned_place_name'].str.len()\n",
    "master_gazetteer_df = places_gdf_all.sort_values(by='name_len', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40de9a924bd3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.539761Z",
     "start_time": "2025-07-26T03:25:04.524873Z"
    }
   },
   "outputs": [],
   "source": [
    "master_gazetteer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788d0301a593ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.689202Z",
     "start_time": "2025-07-26T03:25:04.685374Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预处理：提取地名和省份为列表\n",
    "place_names = master_gazetteer_df['cleaned_place_name'].tolist()\n",
    "provinces = master_gazetteer_df['province'].tolist()\n",
    "\n",
    "def find_best_match_fast(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None, None\n",
    "    for place, province in zip(place_names, provinces):\n",
    "        if place in road_name:\n",
    "            return place, province\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87430e592e4788ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.731092Z",
     "start_time": "2025-07-26T03:25:04.727845Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 迭代匹配（慢）\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "# # tqdm显示进度条\n",
    "# match_results = [find_best_match_fast(name) for name in tqdm(roads_gdf['name'], desc=\"地名匹配\")]\n",
    "#\n",
    "# match_results_df = pd.DataFrame(match_results, columns=['matched_place', 'province'])\n",
    "# final_gdf = pd.concat([roads_gdf, match_results_df], axis=1)\n",
    "# final_gdf = final_gdf.dropna(subset=['province'])\n",
    "# print(f\"精确匹配完成！共找到 {len(final_gdf)} 条与中国地名相关的道路。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f6996bbd8c207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.821565Z",
     "start_time": "2025-07-26T03:25:04.818824Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10041298492ace1",
   "metadata": {},
   "source": [
    "上述结果不是很好：\n",
    "1.  **自我参照噪声**:\n",
    "    *   `121, G1503上海绕城高速, 上海, 上海市`\n",
    "    *   `939, 上海东路, 海东, 青海省`\n",
    "    *   **病因**: 路名中包含“上海”本身。这些道路并不是以外地地名命名的，它们是我们研究中的“噪声”，必须被剔除。第二个例子更糟糕，它把“上海东路”错误地匹配给了青海的“海东”，这是算法的误判。\n",
    "\n",
    "2.  **贪婪的子串匹配**:\n",
    "    *   `376, 金沙江西路, 江西, 江西省`\n",
    "    *   **病因**: 这是最经典、最棘手的错误。“金沙江”是一个完整的地理名词（一条江），但我们的算法因为字典里有“江西”，就贪婪地把它匹配上了。算法没有理解“词”的边界。\n",
    "\n",
    "3.  **不合理的优先顺序**:\n",
    "    *   `982, 松江中山东路, 山东, 山东省`\n",
    "    *   **病因**: 这条路的核心词明显是“中山”，但算法却匹配了“山东”。这可能是因为“山东”和“中山”长度一样，而在我们的排序中，“山东”排在了“中山”前面，导致了错误匹配。也可以看出来松江区可能不是我们的研究重点，需要剔除上海外围地区。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff9f30e49f3c45",
   "metadata": {},
   "source": [
    "## 优化匹配\n",
    "优化思路\n",
    "去掉路名常见后缀，减少干扰；\n",
    "用 Aho-Corasick 自动机一次性批量匹配，提升查找效率；\n",
    "收集所有匹配结果后，按最长优先、最早出现位置来选取最优候选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbdc2a72f5bb89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:22.119759Z",
     "start_time": "2025-07-26T03:33:22.111085Z"
    }
   },
   "outputs": [],
   "source": [
    "import ahocorasick\n",
    "\n",
    "# 1. 清洗路名后缀 字数多的在前！\n",
    "_suffixes = ['路桥', '辅路', '北路', '东路', '南路', \"西路\", \"大道\", '路', '道', '街', '巷', '弄', '浜', '桥', '线', '段']\n",
    "def _clean_road(road):\n",
    "    # 如果只有两个字 则不去掉后缀\n",
    "    if len(road) <= 2:\n",
    "        return road\n",
    "     # 遍历所有后缀，找到匹配的后缀并去掉\n",
    "     # 注意：这里假设后缀列表是按长度降序排列的，这样可以确保最长的后缀优先匹配\n",
    "     # 如果有多个后缀匹配，返回第一个匹配的结果\n",
    "    for s in _suffixes:\n",
    "        if road.endswith(s):\n",
    "            return road[:-len(s)]\n",
    "    return road\n",
    "\n",
    "# 针对路名的最小匹配长度\n",
    "MIN_MATCH_LEN = 2\n",
    "\n",
    "# 构建 Aho-Corasick 自动机，只添加长度 ≥ MIN_MATCH_LEN 的地名\n",
    "A = ahocorasick.Automaton()\n",
    "\n",
    "for name, prov in zip(place_names, provinces):\n",
    "    if len(name) >= MIN_MATCH_LEN:\n",
    "        A.add_word(name, (name, prov))\n",
    "A.make_automaton()\n",
    "\n",
    "# 3. 最优匹配函数：最长优先、最早出现\n",
    "def find_best_match_aho(road):\n",
    "    if not isinstance(road, str):\n",
    "        return None, None\n",
    "\n",
    "    # 返回清理的文本\n",
    "    text = _clean_road(road)\n",
    "    best = None  # (place, prov, length, pos)\n",
    "\n",
    "    for end, (place, prov) in A.iter(text):\n",
    "        length = len(place)\n",
    "\n",
    "        start = end - len(place) + 1\n",
    "        length = len(place)\n",
    "        if not best or length > best[2] or (length == best[2] and start < best[3]):\n",
    "            best = (place, prov, length, start)\n",
    "    return (best[0], best[1]) if best else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877fbd3e3908130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:23.111704Z",
     "start_time": "2025-07-26T03:33:23.017288Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 批量匹配\n",
    "results = [\n",
    "    find_best_match_aho(name)\n",
    "    for name in tqdm(dissolved_roads_in_aoi['name'], desc=\"地名匹配\")\n",
    "]\n",
    "\n",
    "# 2. 转为 DataFrame\n",
    "match_df = pd.DataFrame(results, columns=['matched_place', 'province'])\n",
    "\n",
    "\n",
    "# 构建 clean->原始 place_name 映射\n",
    "mapping = dict(zip(master_gazetteer_df['cleaned_place_name'], master_gazetteer_df['place_name']))\n",
    "\n",
    "# 在 match_df 中新增原始地名列\n",
    "match_df['original_place_name'] = match_df['matched_place'].map(mapping)\n",
    "\n",
    "# 然后再合并最终结果\n",
    "final_gdf = pd.concat([dissolved_roads_in_aoi.reset_index(drop=True), match_df], axis=1)\n",
    "final_gdf = final_gdf.dropna(subset=['province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04d3ab3e0c3507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:23.542837Z",
     "start_time": "2025-07-26T03:33:23.533843Z"
    }
   },
   "outputs": [],
   "source": [
    "final_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bc7ce8b6617f5",
   "metadata": {},
   "source": [
    "大多数都是准确的：而且搜索之后才发现：**“长宁”确实是四川省的一个地名**，准确来说是**四川省宜宾市下辖的“长宁县”**，并非“长宁市”。\n",
    "\n",
    "> 长宁县位于四川盆地南缘，地处宜宾市腹地，因历史上“地势边远宁静”或“希冀民族和睦”而得名，素有“竹子之乡”的美誉。此外，**上海的长宁区**和**长宁路**正是得名于四川的这个“长宁县”。\n",
    "\n",
    "这里补充一些未成功匹配的数据，比如：\n",
    "天山西路,\"LINESTRING (121.34698 31.21907, 121.34755 31.21902, 121.34813 31.21898)\",山西,山西省\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671a11dd659ca6f",
   "metadata": {},
   "source": [
    "# 空间分析与聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ea994283a1f79",
   "metadata": {},
   "source": [
    "##　1. 按省份聚合为“代表点”或“中心线”\n",
    "想做“中国地图缩影”，中观空间分布\n",
    "\n",
    "－　每省份的“所有道路”合并成一个MultiLineString，求其 geometry.centroid 得到“代表点”。\n",
    "－　还可以求“代表线/省份聚合线条”，也就是每省所有命名路段的联合图形（比如用于可视化描边/区域聚合）。\n",
    "－　除几何聚合外，可以统计每省份匹配路段数量，并一起聚合输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0580210a5607a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:25.447145Z",
     "start_time": "2025-07-26T03:33:25.339422Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "\n",
    "# 按省份分组，合并所有道路几何\n",
    "province_group = final_gdf.groupby('province').apply(\n",
    "    lambda df: pd.Series({\n",
    "        'geometry': unary_union(df['geometry']),\n",
    "        'road_count': df['name'].count(),  # 改名为 road_count\n",
    "        'road_names': ', '.join(sorted(df['name'].unique())),  # 保留所有道路名称\n",
    "        'matched_places': ', '.join(sorted(set(df['matched_place'])))  # 改名为 matched_places\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# 计算每省的质心\n",
    "province_group['centroid'] = province_group['geometry'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b1bf6881c6c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:25.988106Z",
     "start_time": "2025-07-26T03:33:25.978004Z"
    }
   },
   "outputs": [],
   "source": [
    "province_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ba060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:26.433510Z",
     "start_time": "2025-07-26T03:33:26.431786Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac1bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:27.008726Z",
     "start_time": "2025-07-26T03:33:26.916397Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分别保存线和点\n",
    "province_group[['province', 'geometry', 'road_count', 'road_names']].to_file(output_filename, layer='province_roads', driver=\"GPKG\", engine='fiona',crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_group[['province', 'centroid', 'road_count', 'road_names']].set_geometry('centroid').to_file(output_filename, layer='province_centroids', driver=\"GPKG\", engine='fiona',crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0c92482c47cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:29.757353Z",
     "start_time": "2025-07-26T03:33:27.565689Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# 设置中文字体和更好的显示参数\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# 创建更大的图形\n",
    "fig, ax = plt.subplots(figsize=(18, 14))\n",
    "\n",
    "# 设置背景色\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "\n",
    "# 1. 绘制聚合线（底层）\n",
    "# 1. 为每个省份分配不同颜色\n",
    "n_provinces = len(province_group)\n",
    "# 使用tab20颜色映射，它有20种不同的颜色\n",
    "\n",
    "\n",
    "colors = cm.tab20(np.linspace(0, 1, n_provinces))\n",
    "\n",
    "# 2. 逐个绘制每个省份的聚合线\n",
    "for idx, (_, row) in enumerate(province_group.iterrows()):\n",
    "    # 创建单个省份的GeoDataFrame\n",
    "    single_province = gpd.GeoDataFrame([row], crs=province_group.crs if hasattr(province_group, 'crs') else None)\n",
    "    \n",
    "    # 绘制该省份的线条\n",
    "    single_province.plot(ax=ax, \n",
    "                        color=colors[idx], \n",
    "                        linewidth=2.5, \n",
    "                        alpha=0.8,\n",
    "                        label=row['province'], \n",
    "                        zorder=1)\n",
    "\n",
    "# 2. 绘制代表点（顶层）- 使用更醒目的红色，增加边框\n",
    "# sizes = province_group['name'] * 15 + 50  # 基础大小50，按道路数量调整\n",
    "\n",
    "province_group.set_geometry('centroid').plot(ax=ax, \n",
    "                                            color='#F24236', \n",
    "                                            markersize=80,\n",
    "                                            edgecolor='white',\n",
    "                                            linewidth=3,\n",
    "                                            label='代表点', \n",
    "                                            zorder=3)\n",
    "\n",
    "# 3. 标注省份名称（最顶层）- 改善文字样式\n",
    "for idx, row in province_group.iterrows():\n",
    "    x, y = row['centroid'].x, row['centroid'].y\n",
    "    \n",
    "    # 添加文字背景框\n",
    "    ax.text(x, y, row['province'], \n",
    "           fontsize=11, \n",
    "           color='#2c3e50',\n",
    "           ha='center', \n",
    "           va='center',\n",
    "           weight='bold',\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                    facecolor='white', \n",
    "                    edgecolor='#bdc3c7',\n",
    "                    alpha=0.9),\n",
    "           zorder=4)\n",
    "\n",
    "# 4. 美化图表\n",
    "ax.set_title(\"上海地名路网空间分布分析\\n各省份道路聚合与代表点位置\", \n",
    "            fontsize=16, \n",
    "            fontweight='bold', \n",
    "            color='#2c3e50',\n",
    "            pad=20)\n",
    "\n",
    "# 设置坐标轴\n",
    "ax.set_xlabel('经度', fontsize=12, color='#34495e')\n",
    "ax.set_ylabel('纬度', fontsize=12, color='#34495e')\n",
    "\n",
    "# 美化网格\n",
    "ax.grid(True, alpha=0.3, color='#bdc3c7', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 美化图例\n",
    "legend = ax.legend(loc='upper right', \n",
    "                  frameon=True, \n",
    "                  fancybox=True, \n",
    "                  shadow=True,\n",
    "                  fontsize=11)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# 设置坐标轴刻度颜色\n",
    "ax.tick_params(colors='#34495e', labelsize=10)\n",
    "\n",
    "# 移除上边框和右边框\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('#bdc3c7')\n",
    "ax.spines['bottom'].set_color('#bdc3c7')\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c115456745e19de",
   "metadata": {},
   "source": [
    "## 4. 空间聚类分析\n",
    "\n",
    "现在我们来分析每个省份的道路在上海的空间分布模式：\n",
    "- 使用KMeans聚类分析每省道路的核心分布区域\n",
    "- 使用DBSCAN识别高密度聚集区\n",
    "- 分析哪些省份呈现\"多核心分布\"特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6fef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:34.911367Z",
     "start_time": "2025-07-26T03:33:34.879099Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.1 准备聚类数据：计算每条道路的质心\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# 为每条道路计算质心坐标\n",
    "final_gdf['centroid'] = final_gdf['geometry'].centroid\n",
    "final_gdf['lon'] = final_gdf['centroid'].x\n",
    "final_gdf['lat'] = final_gdf['centroid'].y\n",
    "\n",
    "print(\"✅ 道路质心计算完成\")\n",
    "print(f\"总计 {len(final_gdf)} 条道路待分析\")\n",
    "\n",
    "# 按省份统计道路数量，选择道路数量较多的省份进行聚类\n",
    "province_stats = final_gdf['province'].value_counts()\n",
    "print(\"\\n📊 各省份道路数量统计：\")\n",
    "print(province_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0cd54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:35.684918Z",
     "start_time": "2025-07-26T03:33:35.678879Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.2 KMeans聚类分析函数\n",
    "def analyze_province_clusters_kmeans(province_name, n_clusters=3, min_roads=5):\n",
    "    \"\"\"\n",
    "    对指定省份的道路进行KMeans聚类分析\n",
    "    \n",
    "    参数:\n",
    "    - province_name: 省份名称\n",
    "    - n_clusters: 聚类数量\n",
    "    - min_roads: 最少道路数量阈值\n",
    "    \"\"\"\n",
    "    \n",
    "    # 筛选该省份的道路\n",
    "    province_roads = final_gdf[final_gdf['province'] == province_name].copy()\n",
    "    \n",
    "    if len(province_roads) < min_roads:\n",
    "        print(f\"⚠️ {province_name} 道路数量不足 ({len(province_roads)} < {min_roads})，跳过聚类\")\n",
    "        return None\n",
    "    \n",
    "    # 提取坐标\n",
    "    coords = province_roads[['lon', 'lat']].values\n",
    "    \n",
    "    # 标准化坐标（重要：避免经纬度尺度差异）\n",
    "    scaler = StandardScaler()\n",
    "    coords_scaled = scaler.fit_transform(coords)\n",
    "    \n",
    "    # KMeans聚类\n",
    "    kmeans = KMeans(n_clusters=min(n_clusters, len(province_roads)), random_state=42)\n",
    "    province_roads.loc[:, 'cluster'] = kmeans.fit_predict(coords_scaled)\n",
    "    \n",
    "    # 计算聚类中心（原始坐标）\n",
    "    cluster_centers = []\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        cluster_coords = coords[province_roads['cluster'] == i]\n",
    "        center_lon = cluster_coords[:, 0].mean()\n",
    "        center_lat = cluster_coords[:, 1].mean()\n",
    "        cluster_size = len(cluster_coords)\n",
    "        cluster_centers.append({\n",
    "            'cluster_id': i,\n",
    "            'center_lon': center_lon,\n",
    "            'center_lat': center_lat,\n",
    "            'road_count': cluster_size,\n",
    "            'roads': province_roads[province_roads['cluster'] == i]['name'].tolist()\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'province': province_name,\n",
    "        'total_roads': len(province_roads),\n",
    "        'n_clusters': kmeans.n_clusters,\n",
    "        'cluster_centers': cluster_centers,\n",
    "        'roads_with_clusters': province_roads\n",
    "    }\n",
    "\n",
    "print(\"✅ KMeans聚类分析函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2abcd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:36.581569Z",
     "start_time": "2025-07-26T03:33:36.575014Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.3 DBSCAN聚类分析函数\n",
    "def analyze_province_clusters_dbscan(province_name, eps=0.01, min_samples=2, min_roads=5):\n",
    "    \"\"\"\n",
    "    对指定省份的道路进行DBSCAN聚类分析\n",
    "    \n",
    "    参数:\n",
    "    - province_name: 省份名称\n",
    "    - eps: DBSCAN的邻域半径参数（经纬度单位，约1km≈0.01度）\n",
    "    - min_samples: 形成聚类的最小样本数\n",
    "    - min_roads: 最少道路数量阈值\n",
    "    \"\"\"\n",
    "    \n",
    "    # 筛选该省份的道路\n",
    "    province_roads = final_gdf[final_gdf['province'] == province_name].copy()\n",
    "    \n",
    "    if len(province_roads) < min_roads:\n",
    "        print(f\"⚠️ {province_name} 道路数量不足 ({len(province_roads)} < {min_roads})，跳过聚类\")\n",
    "        return None\n",
    "    \n",
    "    # 提取坐标\n",
    "    coords = province_roads[['lon', 'lat']].values\n",
    "    \n",
    "    # DBSCAN聚类（不需要标准化，直接使用经纬度）\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    province_roads.loc[:, 'cluster'] = dbscan.fit_predict(coords)\n",
    "    \n",
    "    # 统计聚类结果\n",
    "    unique_clusters = set(province_roads['cluster'])\n",
    "    noise_count = sum(province_roads['cluster'] == -1)  # -1表示噪声点\n",
    "    \n",
    "    # 计算有效聚类中心\n",
    "    cluster_centers = []\n",
    "    for cluster_id in unique_clusters:\n",
    "        if cluster_id == -1:  # 跳过噪声点\n",
    "            continue\n",
    "            \n",
    "        cluster_coords = coords[province_roads['cluster'] == cluster_id]\n",
    "        center_lon = cluster_coords[:, 0].mean()\n",
    "        center_lat = cluster_coords[:, 1].mean()\n",
    "        cluster_size = len(cluster_coords)\n",
    "        \n",
    "        cluster_centers.append({\n",
    "            'cluster_id': cluster_id,\n",
    "            'center_lon': center_lon,\n",
    "            'center_lat': center_lat,\n",
    "            'road_count': cluster_size,\n",
    "            'roads': province_roads[province_roads['cluster'] == cluster_id]['name'].tolist()\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'province': province_name,\n",
    "        'total_roads': len(province_roads),\n",
    "        'n_clusters': len(cluster_centers),\n",
    "        'noise_points': noise_count,\n",
    "        'cluster_centers': cluster_centers,\n",
    "        'roads_with_clusters': province_roads\n",
    "    }\n",
    "\n",
    "print(\"✅ DBSCAN聚类分析函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eae019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:37.532523Z",
     "start_time": "2025-07-26T03:33:37.029406Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.4 批量执行聚类分析\n",
    "# 选择道路数量 >= 8 的省份进行分析\n",
    "target_provinces = province_stats[province_stats >= 8].index.tolist()\n",
    "\n",
    "print(f\"🎯 目标省份：{target_provinces}\")\n",
    "print(f\"总计 {len(target_provinces)} 个省份将进行聚类分析\\n\")\n",
    "\n",
    "# 存储聚类结果\n",
    "kmeans_results = {}\n",
    "dbscan_results = {}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"开始 KMeans 聚类分析...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"\\n🔍 分析 {province}...\")\n",
    "    \n",
    "    # KMeans分析\n",
    "    kmeans_result = analyze_province_clusters_kmeans(province, n_clusters=1)\n",
    "    if kmeans_result:\n",
    "        kmeans_results[province] = kmeans_result\n",
    "        print(f\"✅ KMeans完成: {kmeans_result['n_clusters']} 个聚类中心\")\n",
    "        \n",
    "        # 显示聚类详情\n",
    "        for center in kmeans_result['cluster_centers']:\n",
    "            print(f\"   聚类 {center['cluster_id']}: {center['road_count']} 条道路\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"开始 DBSCAN 聚类分析...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"\\n🔍 分析 {province}...\")\n",
    "    \n",
    "    # DBSCAN分析\n",
    "    dbscan_result = analyze_province_clusters_dbscan(province, eps=0.01, min_samples=2)\n",
    "    if dbscan_result:\n",
    "        dbscan_results[province] = dbscan_result\n",
    "        print(f\"✅ DBSCAN完成: {dbscan_result['n_clusters']} 个聚类中心, {dbscan_result['noise_points']} 个噪声点\")\n",
    "        \n",
    "        # 显示聚类详情\n",
    "        for center in dbscan_result['cluster_centers']:\n",
    "            print(f\"   聚类 {center['cluster_id']}: {center['road_count']} 条道路\")\n",
    "\n",
    "print(\"\\n🎉 聚类分析全部完成！\")\n",
    "print(f\"KMeans结果: {len(kmeans_results)} 个省份\")\n",
    "print(f\"DBSCAN结果: {len(dbscan_results)} 个省份\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a64bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237af8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:39:59.295156Z",
     "start_time": "2025-07-26T03:39:45.906278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.5 可视化聚类结果\n",
    "def plot_province_clusters(province_name, method='both', figsize=(16, 6), show_plot=True):\n",
    "    \"\"\"\n",
    "    可视化特定省份的聚类结果\n",
    "    \n",
    "    参数:\n",
    "    - province_name: 省份名称\n",
    "    - method: 显示方法 ('kmeans', 'dbscan', 'both')\n",
    "    - figsize: 图形大小\n",
    "    - show_plot: 是否显示图形（保存时设为False）\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'both':\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes = [ax1, ax2]\n",
    "        methods = ['kmeans', 'dbscan']\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        axes = [ax]\n",
    "        methods = [method]\n",
    "\n",
    "    # 构造要显示的信息 - 移到标题中\n",
    "    road_count = province_stats[province_name]\n",
    "    sample_roads = ', '.join(final_gdf[final_gdf['province'] == province_name]['name'].unique()[:5])\n",
    "    if len(final_gdf[final_gdf['province'] == province_name]['name'].unique()) > 5:\n",
    "        sample_roads += \"...\"\n",
    "\n",
    "    for i, current_method in enumerate(methods):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # 先绘制上海行政区划底图（只要边界线，不填充）\n",
    "        aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "        aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0, label='上海行政区划')\n",
    "        \n",
    "        # 绘制底图道路 颜色淡一点\n",
    "        dissolved_roads_in_aoi.plot(ax=ax, color='lightgray', linewidth=0.5, alpha=0.5, zorder=0, label='所有道路（合并后）')\n",
    "        \n",
    "        \n",
    "        # 绘制对应的道路\n",
    "        roads = final_gdf[final_gdf['province'] == province_name].copy().geometry\n",
    "        roads.plot(ax=ax, color='black', linewidth=1.5, alpha=1, zorder=1, label='所属道路')\n",
    "\n",
    "\n",
    "        if current_method == 'kmeans' and province_name in kmeans_results:\n",
    "            result = kmeans_results[province_name]\n",
    "            roads_data = result['roads_with_clusters']\n",
    "            title = f\"{province_name} - KMeans聚类 ({result['n_clusters']} 个聚类)\\n道路数量: {road_count} 条 | 示例: {sample_roads}\"\n",
    "\n",
    "            \n",
    "        elif current_method == 'dbscan' and province_name in dbscan_results:\n",
    "            result = dbscan_results[province_name]\n",
    "            roads_data = result['roads_with_clusters']\n",
    "            title = f\"{province_name} - DBSCAN聚类 ({result['n_clusters']} 个聚类)\\n道路数量: {road_count} 条 | 示例: {sample_roads}\"\n",
    "\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"无 {current_method.upper()} 聚类结果\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{province_name} - {current_method.upper()}\")\n",
    "            continue\n",
    "        \n",
    "        # 绘制道路点，按聚类着色\n",
    "        unique_clusters = roads_data['cluster'].unique()\n",
    "        colors = cm.tab10(np.linspace(0, 1, len(unique_clusters)))\n",
    "        \n",
    "        for j, cluster_id in enumerate(unique_clusters):\n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            \n",
    "            if cluster_id == -1:  # DBSCAN的噪声点\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c='green', s=10, alpha=0.8, label='噪声点')\n",
    "            else:\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c=[colors[j]], s=15, alpha=1, label=f'聚类 {cluster_id}')\n",
    "        \n",
    "        # 绘制聚类中心\n",
    "        for center in result['cluster_centers']:\n",
    "            ax.scatter(center['center_lon'], center['center_lat'], \n",
    "                      c='red', s=50, marker='*',\n",
    "                      label='聚类中心' if center['cluster_id'] == result['cluster_centers'][0]['cluster_id'] else \"\")\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('经度')\n",
    "        ax.set_ylabel('纬度')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "     # 只有在show_plot=True时才显示图形\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "        \n",
    "    return fig  # 返回图形对象\n",
    "\n",
    "# 可视化几个代表性省份\n",
    "representative_provinces = ['江苏省', '浙江省', '山东省', '吉林省']\n",
    "\n",
    "for province in representative_provinces:\n",
    "    if province in target_provinces:\n",
    "        print(f\"\\n📊 {province} 聚类结果可视化:\")\n",
    "        plot_province_clusters(province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12f2c5d473980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存所有省份的图标可视化到文件夹\n",
    "from pathlib import Path\n",
    "output_folder = 'image/province_clusters_visualization'\n",
    "\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"📊 正在保存 {province} 的聚类可视化图...\")\n",
    "    \n",
    "    try:\n",
    "        # 创建图形，不显示\n",
    "        fig = plot_province_clusters(province, method='both', figsize=(16, 6), show_plot=False)\n",
    "        \n",
    "        # 保存图形\n",
    "        save_path = Path(output_folder) / f\"{province}_clusters.png\"\n",
    "        fig.savefig(save_path, \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300,\n",
    "                    facecolor='white',\n",
    "                    edgecolor='none')\n",
    "        \n",
    "        print(f\"   ✅ 已保存: {save_path}\")\n",
    "        \n",
    "        # 关闭图形释放内存\n",
    "        plt.close(fig)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 保存失败: {e}\")\n",
    "        # 确保即使出错也关闭图形\n",
    "        plt.close('all')\n",
    "\n",
    "print(f\"✅ 所有聚类可视化图已保存到 '{output_folder}' 文件夹\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02d5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:31:58.932959Z",
     "start_time": "2025-07-26T03:31:58.803693Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.6 聚类结果分析与总结\n",
    "def analyze_clustering_patterns():\n",
    "    \"\"\"\n",
    "    分析各省份的聚类模式，识别多核心分布特征\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🔍 聚类模式分析报告\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 分析KMeans结果\n",
    "    print(\"\\n📊 KMeans聚类分析:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for province, result in kmeans_results.items():\n",
    "        n_clusters = result['n_clusters']\n",
    "        total_roads = result['total_roads']\n",
    "        \n",
    "        # 计算聚类平衡度（各聚类大小的标准差）\n",
    "        cluster_sizes = [center['road_count'] for center in result['cluster_centers']]\n",
    "        balance_score = np.std(cluster_sizes) / np.mean(cluster_sizes) if len(cluster_sizes) > 1 else 0\n",
    "        \n",
    "        distribution_type = \"多核心分布\" if n_clusters >= 3 and balance_score < 0.5 else \\\n",
    "                           \"双核心分布\" if n_clusters == 2 else \"单核心分布\"\n",
    "        \n",
    "        print(f\"{province:8s}: {total_roads:2d}条道路 → {n_clusters}个聚类 ({distribution_type})\")\n",
    "        \n",
    "        # 显示每个聚类的详细信息\n",
    "        for center in result['cluster_centers']:\n",
    "            sample_roads = center['roads']\n",
    "            roads_preview = ', '.join(sample_roads) + ('...' if len(center['roads']) > 3 else '')\n",
    "            print(f\"         聚类{center['cluster_id']}: {center['road_count']}条 - {roads_preview}\")\n",
    "    \n",
    "    # 分析DBSCAN结果\n",
    "    print(f\"\\n📊 DBSCAN聚类分析:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for province, result in dbscan_results.items():\n",
    "        n_clusters = result['n_clusters']\n",
    "        total_roads = result['total_roads']\n",
    "        noise_points = result['noise_points']\n",
    "        \n",
    "        noise_ratio = noise_points / total_roads * 100\n",
    "        \n",
    "        density_type = \"高密度聚集\" if noise_ratio < 20 else \\\n",
    "                      \"中等密度\" if noise_ratio < 50 else \"分散分布\"\n",
    "        \n",
    "        print(f\"{province:8s}: {total_roads:2d}条道路 → {n_clusters}个聚类 + {noise_points}噪声点 ({density_type})\")\n",
    "        \n",
    "        # 显示有效聚类信息\n",
    "        for center in result['cluster_centers']:\n",
    "            sample_roads = center['roads']\n",
    "            roads_preview = ', '.join(sample_roads) + ('...' if len(center['roads']) > 3 else '')\n",
    "            print(f\"         聚类{center['cluster_id']}: {center['road_count']}条 - {roads_preview}\")\n",
    "\n",
    "# 执行聚类模式分析\n",
    "analyze_clustering_patterns()\n",
    "\n",
    "# 4.7 保存聚类结果\n",
    "print(f\"\\n💾 保存聚类分析结果...\")\n",
    "\n",
    "# 保存聚类中心为地理数据\n",
    "all_cluster_centers = []\n",
    "\n",
    "for province, result in kmeans_results.items():\n",
    "    for center in result['cluster_centers']:\n",
    "        all_cluster_centers.append({\n",
    "            'province': province,\n",
    "            'method': 'KMeans',\n",
    "            'cluster_id': center['cluster_id'],\n",
    "            'road_count': center['road_count'],\n",
    "            'center_lon': center['center_lon'],\n",
    "            'center_lat': center['center_lat'],\n",
    "            'geometry': gpd.points_from_xy([center['center_lon']], [center['center_lat']])[0]\n",
    "        })\n",
    "\n",
    "for province, result in dbscan_results.items():\n",
    "    for center in result['cluster_centers']:\n",
    "        all_cluster_centers.append({\n",
    "            'province': province,\n",
    "            'method': 'DBSCAN',\n",
    "            'cluster_id': center['cluster_id'],\n",
    "            'road_count': center['road_count'],\n",
    "            'center_lon': center['center_lon'],\n",
    "            'center_lat': center['center_lat'],\n",
    "            'geometry': gpd.points_from_xy([center['center_lon']], [center['center_lat']])[0]\n",
    "        })\n",
    "\n",
    "# 转换为GeoDataFrame\n",
    "cluster_centers_gdf = gpd.GeoDataFrame(all_cluster_centers, crs='EPSG:4326')\n",
    "\n",
    "# 保存到文件\n",
    "cluster_centers_gdf.to_file(output_filename, layer='cluster_centers', driver=\"GPKG\")\n",
    "\n",
    "print(f\"✅ 聚类中心已保存到 '{output_filename}' 的 'cluster_centers' 图层\")\n",
    "print(f\"📈 总计保存了 {len(cluster_centers_gdf)} 个聚类中心点\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3a0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:46:13.702Z",
     "start_time": "2025-07-26T03:46:11.890943Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "def create_comprehensive_cluster_map(figsize=(20, 16)):\n",
    "    \"\"\"\n",
    "    综合展示行政区边界、道路底图和聚类中心\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "    # 1. 绘制行政区边界\n",
    "    aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "    aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0)\n",
    "\n",
    "    # 2. 绘制所有道路（底层）\n",
    "    dissolved_roads_in_aoi.plot(ax=ax, color='lightgray', linewidth=0.5, alpha=0.5, zorder=2)\n",
    "\n",
    "    # 3. 绘制聚类中心\n",
    "    unique_provinces = list(set(kmeans_results.keys()) | set(dbscan_results.keys()))\n",
    "    colors = cm.tab20(np.linspace(0, 1, len(unique_provinces)))\n",
    "    province_colors = dict(zip(unique_provinces, colors))\n",
    "\n",
    "    for province, result in kmeans_results.items():\n",
    "        color = province_colors[province]\n",
    "        for center in result['cluster_centers']:\n",
    "            ax.scatter(center['center_lon'], center['center_lat'],\n",
    "                       c=[color], s=center['road_count'] * 10 + 50,  # 根据道路数量调整大小\n",
    "                       marker='o', alpha=0.8, edgecolor='white', linewidth=2,\n",
    "                       label=f\"{province} (KMeans)\" if center['cluster_id']==0 else \"\",\n",
    "                       zorder=4)\n",
    "\n",
    "    # 图例和样式\n",
    "    ax.set_title(\"上海地名路网聚类分析\\n各省份道路空间分布模式\", fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('经度'); ax.set_ylabel('纬度')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, frameon=True)\n",
    "    ax.text(0.02, 0.98,\n",
    "            \"● 圆形: KMeans 中心\\n\",\n",
    "            transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.9))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"🗺️ 生成带行政区划、道路和聚类中心的综合地图...\")\n",
    "create_comprehensive_cluster_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad925890",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gdf.drop(columns=['centroid', 'lon', 'lat']).to_file(output_filename, layer=\"matched_roads\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找地名\n",
    "final_gdf.query(\"name == '四川北路'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ef46e01251cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:32:00.525444Z",
     "start_time": "2025-07-26T03:32:00.523301Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 可以根据道路线的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7594e19cfbcf7a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:32:00.575043Z",
     "start_time": "2025-07-26T03:32:00.573255Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.8 区域化分析 - 从点集到区域多边形\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import ConvexHull\n",
    "import alphashape\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_cluster_regions(province_name, method='both', buffer_distance=0.005):\n",
    "    \"\"\"\n",
    "    为指定省份的聚类创建区域多边形\n",
    "    \n",
    "    参数:\n",
    "    - province_name: 省份名称\n",
    "    - method: 使用的聚类方法 ('kmeans', 'dbscan', 'both')\n",
    "    - buffer_distance: 缓冲区距离（经纬度单位，约500米≈0.005度）\n",
    "    \n",
    "    返回:\n",
    "    - 包含区域多边形的字典\n",
    "    \"\"\"\n",
    "    \n",
    "    regions_data = {\n",
    "        'kmeans_regions': [],\n",
    "        'dbscan_regions': [],\n",
    "        'province': province_name\n",
    "    }\n",
    "    \n",
    "    # 处理KMeans聚类区域\n",
    "    if method in ['kmeans', 'both'] and province_name in kmeans_results:\n",
    "        result = kmeans_results[province_name]\n",
    "        roads_data = result['roads_with_clusters']\n",
    "        \n",
    "        for cluster_id in roads_data['cluster'].unique():\n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            points = [(row['lon'], row['lat']) for _, row in cluster_roads.iterrows()]\n",
    "            \n",
    "            region_poly = create_region_polygon(points, buffer_distance)\n",
    "            if region_poly:\n",
    "                regions_data['kmeans_regions'].append({\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'geometry': region_poly,\n",
    "                    'road_count': len(cluster_roads),\n",
    "                    'roads': cluster_roads['name'].tolist(),\n",
    "                    'area_km2': calculate_polygon_area_km2(region_poly)\n",
    "                })\n",
    "    \n",
    "    # 处理DBSCAN聚类区域\n",
    "    if method in ['dbscan', 'both'] and province_name in dbscan_results:\n",
    "        result = dbscan_results[province_name]\n",
    "        roads_data = result['roads_with_clusters']\n",
    "        \n",
    "        for cluster_id in roads_data['cluster'].unique():\n",
    "            if cluster_id == -1:  # 跳过噪声点\n",
    "                continue\n",
    "                \n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            points = [(row['lon'], row['lat']) for _, row in cluster_roads.iterrows()]\n",
    "            \n",
    "            region_poly = create_region_polygon(points, buffer_distance)\n",
    "            if region_poly:\n",
    "                regions_data['dbscan_regions'].append({\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'geometry': region_poly,\n",
    "                    'road_count': len(cluster_roads),\n",
    "                    'roads': cluster_roads['name'].tolist(),\n",
    "                    'area_km2': calculate_polygon_area_km2(region_poly)\n",
    "                })\n",
    "    \n",
    "    return regions_data\n",
    "\n",
    "def create_region_polygon(points, buffer_distance=0.005, method='convex_hull'):\n",
    "    \"\"\"\n",
    "    从点集创建区域多边形\n",
    "    \n",
    "    参数:\n",
    "    - points: 点坐标列表 [(lon, lat), ...]\n",
    "    - buffer_distance: 缓冲区距离\n",
    "    - method: 'convex_hull', 'alpha_shape', 'buffer_union'\n",
    "    \n",
    "    返回:\n",
    "    - Shapely Polygon对象\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(points) < 3:\n",
    "        # 点数不足，创建缓冲区\n",
    "        if len(points) == 1:\n",
    "            point = Point(points[0])\n",
    "            return point.buffer(buffer_distance)\n",
    "        elif len(points) == 2:\n",
    "            from shapely.geometry import LineString\n",
    "            line = LineString(points)\n",
    "            return line.buffer(buffer_distance)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if method == 'convex_hull':\n",
    "            # 方法1: 凸包 + 缓冲区（最稳定）\n",
    "            hull = ConvexHull(points)\n",
    "            hull_points = [points[i] for i in hull.vertices]\n",
    "            polygon = Polygon(hull_points)\n",
    "            return polygon.buffer(buffer_distance)\n",
    "            \n",
    "        elif method == 'alpha_shape':\n",
    "            # 方法2: Alpha Shape（更贴合实际形状，但可能不稳定）\n",
    "            try:\n",
    "                alpha_shape = alphashape.alphashape(points, 0.1)\n",
    "                if alpha_shape.geom_type == 'Polygon':\n",
    "                    return alpha_shape.buffer(buffer_distance)\n",
    "                elif alpha_shape.geom_type == 'MultiPolygon':\n",
    "                    # 取最大的多边形\n",
    "                    largest = max(alpha_shape.geoms, key=lambda x: x.area)\n",
    "                    return largest.buffer(buffer_distance)\n",
    "            except:\n",
    "                # Alpha shape失败，回退到凸包\n",
    "                hull = ConvexHull(points)\n",
    "                hull_points = [points[i] for i in hull.vertices]\n",
    "                polygon = Polygon(hull_points)\n",
    "                return polygon.buffer(buffer_distance)\n",
    "                \n",
    "        elif method == 'buffer_union':\n",
    "            # 方法3: 点缓冲区联合（适合分散分布）\n",
    "            buffered_points = [Point(p).buffer(buffer_distance) for p in points]\n",
    "            union_result = unary_union(buffered_points)\n",
    "            return union_result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"创建多边形失败: {e}\")\n",
    "        # 失败时创建简单缓冲区联合\n",
    "        try:\n",
    "            buffered_points = [Point(p).buffer(buffer_distance) for p in points]\n",
    "            return unary_union(buffered_points)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def calculate_polygon_area_km2(polygon):\n",
    "    \"\"\"\n",
    "    计算多边形面积（平方公里）\n",
    "    注意：这是一个近似计算，适用于小范围区域\n",
    "    \"\"\"\n",
    "    if polygon is None:\n",
    "        return 0\n",
    "        \n",
    "    # 将度转换为米的近似系数（在上海纬度附近）\n",
    "    lat_to_m = 111000  # 1度纬度 ≈ 111km\n",
    "    lon_to_m = 91000   # 1度经度 ≈ 91km（在北纬31度附近）\n",
    "    \n",
    "    # 获取边界框\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    \n",
    "    # 简单的面积估算（矩形近似）\n",
    "    width_m = (maxx - minx) * lon_to_m\n",
    "    height_m = (maxy - miny) * lat_to_m\n",
    "    \n",
    "    # 更精确的方法：使用Shapely的面积并转换\n",
    "    area_deg2 = polygon.area\n",
    "    area_m2 = area_deg2 * lat_to_m * lon_to_m\n",
    "    area_km2 = area_m2 / 1000000\n",
    "    \n",
    "    return round(area_km2, 3)\n",
    "\n",
    "print(\"✅ 区域化分析函数定义完成\")\n",
    "\n",
    "# 为所有目标省份创建区域多边形\n",
    "print(\"\\n🗺️ 开始创建聚类区域多边形...\")\n",
    "\n",
    "all_regions_data = {}\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"🔍 处理 {province} 的区域化...\")\n",
    "    regions = create_cluster_regions(province, method='both', buffer_distance=0.003)\n",
    "    all_regions_data[province] = regions\n",
    "    \n",
    "    kmeans_count = len(regions['kmeans_regions'])\n",
    "    dbscan_count = len(regions['dbscan_regions'])\n",
    "    print(f\"   ✅ KMeans: {kmeans_count} 个区域, DBSCAN: {dbscan_count} 个区域\")\n",
    "\n",
    "print(\"\\n🎉 区域化处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd0f92878936e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.9 可视化聚类区域\n",
    "def plot_province_cluster_regions(province_name, method='both', figsize=(16, 6), show_plot=True):\n",
    "    \"\"\"\n",
    "    可视化特定省份的聚类区域多边形\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'both':\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes = [ax1, ax2]\n",
    "        methods = ['kmeans', 'dbscan']\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        axes = [ax]\n",
    "        methods = [method]\n",
    "\n",
    "    # 获取区域数据\n",
    "    regions_data = all_regions_data.get(province_name, {})\n",
    "    road_count = province_stats[province_name]\n",
    "    sample_roads = ', '.join(final_gdf[final_gdf['province'] == province_name]['name'].unique()[:5])\n",
    "    if len(final_gdf[final_gdf['province'] == province_name]['name'].unique()) > 5:\n",
    "        sample_roads += \"...\"\n",
    "\n",
    "    for i, current_method in enumerate(methods):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # 绘制上海行政区划底图\n",
    "        aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "        aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0)\n",
    "        \n",
    "        # 绘制所有道路（背景）\n",
    "        roads_in_aoi_gdf.plot(ax=ax, color='lightgray', linewidth=0.3, alpha=0.4, zorder=1)\n",
    "\n",
    "        if current_method == 'kmeans':\n",
    "            regions = regions_data.get('kmeans_regions', [])\n",
    "            title = f\"{province_name} - KMeans 聚类区域 ({len(regions)} 个区域)\\n 示例: {sample_roads}\"\n",
    "        else:\n",
    "            regions = regions_data.get('dbscan_regions', [])\n",
    "            title = f\"{province_name} - DBSCAN 聚类区域 ({len(regions)} 个区域)\\n 示例: {sample_roads}\"\n",
    "\n",
    "        if not regions:\n",
    "            ax.text(0.5, 0.5, f\"无 {current_method.upper()} 聚类区域\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(title)\n",
    "            continue\n",
    "        \n",
    "        # 绘制聚类区域多边形\n",
    "        colors = cm.tab10(np.linspace(0, 1, len(regions)))\n",
    "        \n",
    "        for j, region in enumerate(regions):\n",
    "            # 创建GeoDataFrame来绘制多边形\n",
    "            region_gdf = gpd.GeoDataFrame([region], crs='EPSG:4326')\n",
    "            \n",
    "            # 绘制多边形区域（半透明填充）\n",
    "            region_gdf.plot(ax=ax, \n",
    "                           color=colors[j], \n",
    "                           alpha=0.3, \n",
    "                           edgecolor=colors[j], \n",
    "                           linewidth=2,\n",
    "                           label=f\"聚类 {region['cluster_id']} ({region['road_count']}条路)\",\n",
    "                           zorder=3)\n",
    "            \n",
    "            # 在区域中心添加标注\n",
    "            centroid = region['geometry'].centroid\n",
    "            ax.annotate(f\"C{region['cluster_id']}\\n{region['road_count']}条\\n{region['area_km2']}km²\",\n",
    "                       (centroid.x, centroid.y),\n",
    "                       ha='center', va='center',\n",
    "                       fontsize=8, weight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                               facecolor='white', \n",
    "                               alpha=0.8,\n",
    "                               edgecolor=colors[j]),\n",
    "                       zorder=5)\n",
    "        \n",
    "        # 绘制道路点\n",
    "        if current_method == 'kmeans' and province_name in kmeans_results:\n",
    "            roads_data = kmeans_results[province_name]['roads_with_clusters']\n",
    "        elif current_method == 'dbscan' and province_name in dbscan_results:\n",
    "            roads_data = dbscan_results[province_name]['roads_with_clusters']\n",
    "        else:\n",
    "            roads_data = None\n",
    "            \n",
    "        if roads_data is not None:\n",
    "            for cluster_id in roads_data['cluster'].unique():\n",
    "                if cluster_id == -1:  # 跳过DBSCAN噪声点\n",
    "                    continue\n",
    "                cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "                color_idx = cluster_id if cluster_id < len(colors) else cluster_id % len(colors)\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c=[colors[color_idx]], s=15, alpha=0.8, \n",
    "                          edgecolor='white', linewidth=0.5,\n",
    "                          zorder=4)\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('经度')\n",
    "        ax.set_ylabel('纬度')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    return fig\n",
    "\n",
    "# 可视化几个代表性省份的区域\n",
    "representative_provinces = ['江苏省', '浙江省', '山东省', '安徽省']\n",
    "\n",
    "for province in representative_provinces:\n",
    "    if province in target_provinces:\n",
    "        print(f\"\\n📊 {province} 聚类区域可视化:\")\n",
    "        plot_province_cluster_regions(province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536b5abacfaf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.10 保存区域化结果\n",
    "def save_cluster_regions():\n",
    "    \"\"\"\n",
    "    保存所有聚类区域为地理数据文件\n",
    "    \"\"\"\n",
    "    \n",
    "    # 准备KMeans区域数据\n",
    "    kmeans_regions_list = []\n",
    "    for province, regions_data in all_regions_data.items():\n",
    "        for region in regions_data['kmeans_regions']:\n",
    "            kmeans_regions_list.append({\n",
    "                'province': province,\n",
    "                'method': 'KMeans',\n",
    "                'cluster_id': region['cluster_id'],\n",
    "                'road_count': region['road_count'],\n",
    "                'area_km2': region['area_km2'],\n",
    "                'roads_sample': ', '.join(region['roads'][:5]) + ('...' if len(region['roads']) > 5 else ''),\n",
    "                'geometry': region['geometry']\n",
    "            })\n",
    "    \n",
    "    # 准备DBSCAN区域数据\n",
    "    dbscan_regions_list = []\n",
    "    for province, regions_data in all_regions_data.items():\n",
    "        for region in regions_data['dbscan_regions']:\n",
    "            dbscan_regions_list.append({\n",
    "                'province': province,\n",
    "                'method': 'DBSCAN',\n",
    "                'cluster_id': region['cluster_id'],\n",
    "                'road_count': region['road_count'],\n",
    "                'area_km2': region['area_km2'],\n",
    "                'roads_sample': ', '.join(region['roads'][:5]) + ('...' if len(region['roads']) > 5 else ''),\n",
    "                'geometry': region['geometry']\n",
    "            })\n",
    "    \n",
    "    # 保存为GeoDataFrame\n",
    "    if kmeans_regions_list:\n",
    "        kmeans_regions_gdf = gpd.GeoDataFrame(kmeans_regions_list, crs='EPSG:4326')\n",
    "        kmeans_regions_gdf.to_file(output_filename, layer='kmeans_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"✅ KMeans区域已保存: {len(kmeans_regions_gdf)} 个区域\")\n",
    "    \n",
    "    if dbscan_regions_list:\n",
    "        dbscan_regions_gdf = gpd.GeoDataFrame(dbscan_regions_list, crs='EPSG:4326')\n",
    "        dbscan_regions_gdf.to_file(output_filename, layer='dbscan_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"✅ DBSCAN区域已保存: {len(dbscan_regions_gdf)} 个区域\")\n",
    "    \n",
    "    # 合并所有区域\n",
    "    all_regions_list = kmeans_regions_list + dbscan_regions_list\n",
    "    if all_regions_list:\n",
    "        all_regions_gdf = gpd.GeoDataFrame(all_regions_list, crs='EPSG:4326')\n",
    "        all_regions_gdf.to_file(output_filename, layer='all_cluster_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"✅ 所有聚类区域已保存: {len(all_regions_gdf)} 个区域\")\n",
    "\n",
    "# 执行保存\n",
    "print(\"\\n💾 保存区域化结果...\")\n",
    "save_cluster_regions()\n",
    "\n",
    "# 统计区域化结果\n",
    "print(\"\\n📊 区域化统计总结:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_kmeans_regions = 0\n",
    "total_dbscan_regions = 0\n",
    "total_area_kmeans = 0\n",
    "total_area_dbscan = 0\n",
    "\n",
    "for province, regions_data in all_regions_data.items():\n",
    "    kmeans_count = len(regions_data['kmeans_regions'])\n",
    "    dbscan_count = len(regions_data['dbscan_regions'])\n",
    "    \n",
    "    kmeans_area = sum(r['area_km2'] for r in regions_data['kmeans_regions'])\n",
    "    dbscan_area = sum(r['area_km2'] for r in regions_data['dbscan_regions'])\n",
    "    \n",
    "    total_kmeans_regions += kmeans_count\n",
    "    total_dbscan_regions += dbscan_count\n",
    "    total_area_kmeans += kmeans_area\n",
    "    total_area_dbscan += dbscan_area\n",
    "    \n",
    "    print(f\"{province:8s}: KMeans {kmeans_count:2d}区域({kmeans_area:5.1f}km²) | DBSCAN {dbscan_count:2d}区域({dbscan_area:5.1f}km²)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"总计: KMeans {total_kmeans_regions}区域({total_area_kmeans:.1f}km²) | DBSCAN {total_dbscan_regions}区域({total_area_dbscan:.1f}km²)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ac71fe7902c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.11 保存区域可视化图片\n",
    "print(\"\\n📊 保存所有省份的区域可视化图...\")\n",
    "\n",
    "# 创建区域可视化文件夹\n",
    "regions_output_folder = 'image/province_cluster_regions_visualization'\n",
    "Path(regions_output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for province in target_provinces:\n",
    "    if province in all_regions_data:\n",
    "        print(f\"📊 正在保存 {province} 的聚类区域图...\")\n",
    "        \n",
    "        # 创建图形\n",
    "        fig = plot_province_cluster_regions(province, method='both', figsize=(16, 6), show_plot=False)\n",
    "        \n",
    "        \n",
    "        # 保存图形\n",
    "        plt.savefig(Path(regions_output_folder) / f\"{province}_cluster_regions.png\", \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300,\n",
    "                    facecolor='white')\n",
    "        \n",
    "        # 关闭图形释放内存\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"✅ 所有聚类区域可视化图已保存到 '{regions_output_folder}' 文件夹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48875286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shanghai-road-clustering-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
