{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d047ef",
   "metadata": {},
   "source": [
    "# ä¸€ å®‰è£…ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d406e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:51.290032Z",
     "start_time": "2025-07-26T03:24:51.286278Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ‰§è¡Œä»£ç \n",
    "# !uv init . --name \"shanghai_road_clustering_analysis\"\n",
    "# !uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff817797",
   "metadata": {},
   "source": [
    "# äºŒ æ”¶é›†å¹¶ä¸”æ£€æŸ¥æ•°æ®\n",
    "åŸå§‹æ•°æ®åˆ†ä¸ºä¸¤ä¸ªï¼Œè§£å‹è·å–ã€‚\n",
    "[é“è·¯æ•°æ®ï¼š](data/SHPæ ¼å¼è·¯ç½‘.7z)\n",
    "[çœä»½ä¸å¸‚åŒºå¿çš„å­—å…¸åŸå§‹æ•°æ®](data/çœä»½ä¸å¸‚åŒºå¿çš„æ•°æ®.7z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a68fb3",
   "metadata": {},
   "source": [
    "## é“è·¯æ•°æ®\n",
    "å›¾ç®€å•ç”¨äº†ç½‘ä¸Šä¸‹è½½çš„æ•°æ®ï¼šhttps://mp.weixin.qq.com/s/TEOYs2PJwX4PaN6tKJ3udg\n",
    "> è¯´æ˜ï¼šâ€œæœ¬æ¬¡åˆ†äº«ä¸Šæµ·å¸‚è·¯ç½‘æ•°æ®ï¼ŒåŒ…å«SHPæ ¼å¼å’Œâ€œæ¨¡å‹æ ¼å¼â€ã€‚GCJ02åæ ‡ç³»ï¼Œå…±363398æ¡è·¯æ®µï¼Œç´¯è®¡36666å…¬é‡Œã€‚å·²ç»å¤„ç†å¥½æ‹“æ‰‘å…³ç³»å’Œè¿é€šæ€§ï¼Œå¯å¯¼å…¥ArcMapã€TransCADæˆ–SUMOç­‰äº¤é€šæ¨¡å‹å·¥å…·ç”Ÿæˆè·¯ç½‘æ¨¡å‹ï¼Œç”¨äºè·¯å¾„è§„åˆ’å’Œäº¤é€šä»¿çœŸã€‚è·¯ç½‘ç¤ºæ„å›¾è§å›¾1ã€‚â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20dfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:55.819599Z",
     "start_time": "2025-07-26T03:24:51.538961Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç°æœ‰çš„ `SH_LINK.shp` æ•°æ®è´¨é‡\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "roads_gdf = gpd.read_file(r'data\\ä¸Šæµ·è·¯ç½‘æ•°æ®\\ä¸Šæµ·è·¯ç½‘æ•°æ®\\SHPæ ¼å¼è·¯ç½‘\\SH_LINK.shp') \n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b955268b252dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:55.872899Z",
     "start_time": "2025-07-26T03:24:55.867755Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç©ºé—´å‚è€ƒ æ˜¾ç¤ºæ˜¯4326 å› ä¸ºæˆ‘ä»¬åšè·¯ç½‘èšç±»ï¼Œæˆ‘å°±ä¸å»æ·±ç©¶åæ ‡ç³»å¯¹ä¸å¯¹äº†\n",
    "roads_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec3559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:56.023816Z",
     "start_time": "2025-07-26T03:24:56.007330Z"
    }
   },
   "outputs": [],
   "source": [
    "# é¢„å¤„ç†æ•°æ®\n",
    "# é€‰å–éœ€è¦çš„å­—æ®µ\n",
    "roads_gdf = roads_gdf[['ROAD', 'geometry']]\n",
    "# é‡å‘½åå­—æ®µ\n",
    "roads_gdf.rename(columns={'ROAD': 'name'}, inplace=True)\n",
    "\n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ad1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾æ‰¾å—äº¬è¥¿è·¯\n",
    "roads_gdf.query(\"name == 'å—äº¬è¥¿è·¯'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ æ‰ name ä¸ºç©ºçš„è¡Œ\n",
    "roads_gdf = roads_gdf[roads_gdf['name'].notna()]\n",
    "roads_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acc0ad",
   "metadata": {},
   "source": [
    "### é™å®šç ”ç©¶èŒƒå›´åˆ°ä¸Šæµ·å¸‚ä¸­å¿ƒçš„å‡ ä¸ªåŒº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd50614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. é™å®šé“è·¯èŒƒå›´ åªå¯¹ä¸Šæµ·ä¸­å¿ƒåŸåŒºè¿›è¡ŒåŒ¹é…ï¼Œè¿™æ˜¯1945å¹´é‚£åœºå¤§è§„æ¨¡è·¯åæ”¹é©çš„æ ¸å¿ƒåœ°å¸¦\n",
    "districts_gdf = gpd.read_file(r'data\\çœä»½ä¸å¸‚åŒºå¿çš„æ•°æ®\\åˆ†å¹´é¾„ã€æ€§åˆ«çš„äººå£_åŒºå¿ç­‰çº§.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97088818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç©ºé—´å‚è€ƒ\n",
    "districts_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_gdf = districts_gdf[districts_gdf['çœçº§'] == 'ä¸Šæµ·å¸‚'].copy()\n",
    "\n",
    "# é€‰æ‹©éœ€è¦çš„å­—æ®µ\n",
    "districts_gdf = districts_gdf[['åœ°å', 'geometry']].copy()\n",
    "\n",
    "CENTRAL_DISTRICTS = ['é»„æµ¦åŒº', 'å¾æ±‡åŒº', 'é•¿å®åŒº', 'é™å®‰åŒº', 'æ™®é™€åŒº', 'è™¹å£åŒº', 'æ¨æµ¦åŒº']\n",
    "\n",
    "# è¿‡æ»¤å‡ºä¸­å¿ƒåŸåŒº\n",
    "central_districts_gdf = districts_gdf[districts_gdf[\"åœ°å\"].isin(CENTRAL_DISTRICTS)]\n",
    "\n",
    "# åˆå¹¶ä¸­å¿ƒåŸåŒºè¾¹ç•Œä»¥åˆ›å»ºç ”ç©¶èŒƒå›´ (A\n",
    "aoi_polygon = central_districts_gdf.union_all()\n",
    "\n",
    "aoi_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc703df",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_polygon_df = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=central_districts_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"data/shanghai_roads_merged.gpkg\"\n",
    "\n",
    "aoi_polygon_df.to_file(output_filename, layer='shanghai_selected_districts', driver=\"GPKG\", engine='fiona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç©ºé—´ç´¢å¼•ç­›é€‰ä½äºç ”ç©¶èŒƒå›´å†…çš„é“è·¯\n",
    "roads_in_aoi_gdf = gpd.sjoin(roads_gdf, gpd.GeoDataFrame(geometry=[aoi_polygon], crs=central_districts_gdf.crs), how=\"inner\", predicate='intersects')\n",
    "# sjoinä¼šæ·»åŠ ä¸€ä¸ª'index_right'åˆ—ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒå»æ‰\n",
    "roads_in_aoi_gdf = roads_in_aoi_gdf.drop(columns=['index_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d90a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_in_aoi_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59284d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_in_aoi_gdf.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf4dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T09:54:58.456437Z",
     "start_time": "2025-07-24T09:54:58.439576Z"
    }
   },
   "source": [
    "ä»OpenStreetMapç­‰æ ‡å‡†æ¥æºä¸‹è½½çš„è·¯ç½‘æ•°æ®ï¼Œä¸ºäº†ä¿è¯ç½‘ç»œçš„æ‹“æ‰‘å…³ç³»ï¼ˆå³ï¼ŒçŸ¥é“å“ªæ¡è·¯å’Œå“ªæ¡è·¯æ˜¯è¿é€šçš„ï¼‰ï¼Œåœ¨æ¯ä¸€ä¸ªäº¤å‰å£ï¼Œè·¯æ®µï¼ˆLineStringï¼‰éƒ½å¿…é¡»è¢«æ‰“æ–­æˆç‹¬ç«‹çš„å°æ®µã€‚å¦‚æœæˆ‘ä»¬ä¸ºâ€œå—äº¬è¥¿è·¯â€çš„æ¯ä¸€å°æ®µéƒ½è®¡ç®—ä¸€ä¸ªè´¨å¿ƒï¼Œé‚£ä¹ˆåœ¨â€œå—äº¬è¥¿è·¯â€è¿™æ¡è·¯ä¸Šå°±ä¼šäº§ç”Ÿå¯†å¯†éº»éº»å‡ åä¸ªç‚¹ï¼Œè¿™ä¼šç»™èšç±»åˆ†æå¸¦æ¥å·¨å¤§çš„å™ªå£°å’Œæƒé‡åå·®ã€‚ä¹Ÿä¼šäº§ç”Ÿå¯è§†åŒ–æ··ä¹±ã€‚\n",
    "è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦åœ¨åˆ†ææµç¨‹ä¸­å¢åŠ ä¸€ä¸ªå…³é”®çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤â€”â€”é“è·¯åˆå¹¶ã€‚\n",
    "\n",
    "### é“è·¯åˆå¹¶\n",
    "è¿™ä¸ªæ“ä½œçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šå°†æ‰€æœ‰æ‹¥æœ‰ç›¸åŒè·¯å (name å­—æ®µç›¸åŒ) å¹¶ä¸”åœ¨ç©ºé—´ä¸Šèƒ½å¤Ÿé¦–å°¾ç›¸æ¥çš„é›¶æ•£çº¿æ®µï¼Œåˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„ã€æ›´é•¿çš„å‡ ä½•å¯¹è±¡ï¼ˆMultiLineStringï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f9118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:58.374260Z",
     "start_time": "2025-07-26T03:24:56.112911Z"
    }
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Geopandas çš„ Dissolve åŠŸèƒ½\n",
    "# æˆ‘ä»¬å‘Šè¯‰geopandasï¼ŒæŒ‰'name'å­—æ®µè¿›è¡Œåˆ†ç»„ã€‚\n",
    "# å¯¹äºæ¯ä¸ªåˆ†ç»„ï¼ˆå³æ‰€æœ‰åŒåçš„è·¯æ®µï¼‰ï¼Œå®ƒä¼šè‡ªåŠ¨å°†å®ƒä»¬çš„å‡ ä½•å›¾å½¢åˆå¹¶ã€‚\n",
    "# reset_index() æ˜¯ä¸ºäº†å°†'name'ä»ç´¢å¼•å˜å›æ™®é€šçš„åˆ—\n",
    "dissolved_roads_in_aoi = roads_in_aoi_gdf.dissolve(by='name').reset_index()\n",
    "dissolved_roads_in_aoi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273e603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:24:58.453045Z",
     "start_time": "2025-07-26T03:24:58.449010Z"
    }
   },
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹é“è·¯åˆå¹¶å‰åçš„æ•°æ®å·®è·\n",
    "print(f\"åŸå§‹æ•°æ®è¡Œæ•°: {len(roads_in_aoi_gdf)}\")\n",
    "print(f\"åˆå¹¶åæ•°æ®è¡Œæ•°: {len(dissolved_roads_in_aoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e96b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:00.474604Z",
     "start_time": "2025-07-26T03:24:58.624292Z"
    }
   },
   "outputs": [],
   "source": [
    "# å¤„ç†åˆå¹¶åçš„å‡ ä½•å¯¹è±¡ å°è¯•å°† MultiLineString åˆå¹¶ä¸ºå•ä¸€çš„ LineString\n",
    "from shapely.ops import linemerge, unary_union\n",
    "\n",
    "def merge_lines(geom):\n",
    "    \"\"\"\n",
    "    å°è¯•å°†MultiLineStringåˆå¹¶ä¸ºå•ä¸€LineString\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # æ£€æŸ¥å‡ ä½•ç±»å‹\n",
    "        if geom.geom_type == 'LineString':\n",
    "            # å·²ç»æ˜¯LineStringï¼Œç›´æ¥è¿”å›\n",
    "            return geom\n",
    "        elif geom.geom_type == 'MultiLineString':\n",
    "            # å…ˆä½¿ç”¨unary_unionæ¸…ç†å‡ ä½•å¯¹è±¡ï¼Œå¤„ç†å¯èƒ½çš„é‡å æˆ–è‡ªç›¸äº¤\n",
    "            cleaned_geom = unary_union(geom)\n",
    "            \n",
    "            # å°è¯•ä½¿ç”¨linemergeåˆå¹¶è¿æ¥çš„çº¿æ®µ\n",
    "            merged = linemerge(cleaned_geom)\n",
    "            \n",
    "            # linemergeå¯èƒ½è¿”å›LineStringæˆ–MultiLineString\n",
    "            return merged\n",
    "        else:\n",
    "            # å…¶ä»–å‡ ä½•ç±»å‹ï¼Œç›´æ¥è¿”å›\n",
    "            return geom\n",
    "    except Exception as e:\n",
    "        print(f\"åˆå¹¶å¤±è´¥ï¼Œä¿ç•™åŸå§‹å‡ ä½•: {e}\")\n",
    "        return geom\n",
    "\n",
    "# åº”ç”¨åˆå¹¶å‡½æ•°å‰ï¼Œå…ˆæ£€æŸ¥å‡ ä½•ç±»å‹åˆ†å¸ƒ\n",
    "print(\"=== åˆå¹¶å‰å‡ ä½•ç±»å‹åˆ†å¸ƒ ===\")\n",
    "geom_types = dissolved_roads_in_aoi['geometry'].apply(lambda x: x.geom_type).value_counts()\n",
    "print(geom_types)\n",
    "\n",
    "# åº”ç”¨åˆå¹¶å‡½æ•°\n",
    "print(\"\\næ­£åœ¨å¤„ç†å‡ ä½•åˆå¹¶...\")\n",
    "dissolved_roads_in_aoi['geometry'] = dissolved_roads_in_aoi['geometry'].apply(merge_lines)\n",
    "\n",
    "# æ£€æŸ¥åˆå¹¶åçš„å‡ ä½•ç±»å‹åˆ†å¸ƒ\n",
    "print(\"\\n=== åˆå¹¶åå‡ ä½•ç±»å‹åˆ†å¸ƒ ===\")\n",
    "geom_types_after = dissolved_roads_in_aoi['geometry'].apply(lambda x: x.geom_type).value_counts()\n",
    "print(geom_types_after)\n",
    "\n",
    "print(\"âœ… å‡ ä½•åˆå¹¶å¤„ç†å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab14f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:00.850626Z",
     "start_time": "2025-07-26T03:25:00.492542Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"âœ… é“è·¯åˆå¹¶å¤„ç†å®Œæˆï¼\")\n",
    "\n",
    "# --- 4. ä¿å­˜ç»“æœ ---\n",
    "\n",
    "dissolved_roads_in_aoi.to_file(output_filename, layer='merged_roads_in_aoi', driver=\"GPKG\", engine='fiona') # ç¡®ä¿ä½¿ç”¨ 'fiona' å¼•æ“ ä¸ç„¶ç”¨arcgisproæ‰“ä¸å¼€ bugï¼Ÿ\n",
    "print(f\"âœ… åˆå¹¶åçš„è·¯ç½‘æ•°æ®å·²ä¿å­˜åˆ° '{output_filename}'\")\n",
    "\n",
    "print(\"\\nğŸ“Š åˆå¹¶åæ•°æ®é¢„è§ˆ:\")\n",
    "print(dissolved_roads_in_aoi[['name', 'geometry']].head().to_string())\n",
    "print(f\"\\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:\")\n",
    "print(f\"åŸå§‹é“è·¯æ•°é‡: {len(roads_in_aoi_gdf)}\")\n",
    "print(f\"åˆå¹¶åé“è·¯æ•°é‡: {len(dissolved_roads_in_aoi)}\")\n",
    "print(f\"æ•°æ®å‹ç¼©ç‡: {(1 - len(dissolved_roads_in_aoi)/len(roads_in_aoi_gdf))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸå§‹è·¯ç½‘æˆ‘ä»¬èåˆä¹‹åä¹Ÿä¿å­˜ä¸€ä»½\n",
    "all_roads_gdf_dissolve = roads_gdf.dissolve(by='name').reset_index()\n",
    "all_roads_gdf_dissolve.to_file(output_filename, layer='all_shanghai_roads', driver=\"GPKG\", engine='fiona')\n",
    "print(f\"âœ… åŸå§‹è·¯ç½‘æ•°æ®å·²ä¿å­˜åˆ° '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1b5d0",
   "metadata": {},
   "source": [
    "## æ„å»ºåœ°åè¯å…¸\n",
    "ä»ä»¥å¾€çš„çœå¸‚å¿shpä¸­æå–\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cc41ed47fc5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.155187Z",
     "start_time": "2025-07-26T03:25:00.874256Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf = gpd.read_file(r\"data\\çœä»½ä¸å¸‚åŒºå¿çš„æ•°æ®\\åˆ†å¹´é¾„ã€æ€§åˆ«çš„äººå£_åŒºå¿ç­‰çº§.shp\")\n",
    "\n",
    "places_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb8ff20275c18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.207740Z",
     "start_time": "2025-07-26T03:25:01.203333Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç©ºé—´å‚è€ƒ\n",
    "places_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8b5edc9964284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.458792Z",
     "start_time": "2025-07-26T03:25:01.453670Z"
    }
   },
   "outputs": [],
   "source": [
    "# å…ˆåˆ‡ç‰‡å†å¤åˆ¶\n",
    "places_gdf = places_gdf[['åœ°å', 'çœçº§', 'geometry']].copy()\n",
    "\n",
    "# é‡å‘½åå­—æ®µ\n",
    "places_gdf.rename(columns={'åœ°å': 'place_name', 'çœçº§': 'province'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fd88e7ffa4b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.623566Z",
     "start_time": "2025-07-26T03:25:01.597176Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583f3dbf8cdbed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.692171Z",
     "start_time": "2025-07-26T03:25:01.674060Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "province_gdf = places_gdf[['province']].drop_duplicates().copy()\n",
    "\n",
    "# å‰”é™¤ä¸Šæµ·å¸‚\n",
    "province_gdf = province_gdf[province_gdf['province'] != 'ä¸Šæµ·å¸‚'].copy()\n",
    "\n",
    "# å°†çœä»½æœ¬èº«ä¹ŸåŠ å…¥åˆ°åœ°åæ€»è¡¨ä¸­\n",
    "province_gdf['place_name'] = province_gdf['province']\n",
    "\n",
    "\n",
    "# è°ƒæ•´åˆ—é¡ºåºä¸åŸè¡¨ä¸€è‡´\n",
    "province_gdf = province_gdf[['place_name', 'province']]\n",
    "\n",
    "# åˆå¹¶çœä»½å’ŒåŸæœ‰åœ°åè¡¨\n",
    "places_gdf_all = pd.concat([places_gdf, province_gdf], ignore_index=True)\n",
    "\n",
    "places_gdf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933890014def1ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:01.919003Z",
     "start_time": "2025-07-26T03:25:01.908631Z"
    }
   },
   "outputs": [],
   "source": [
    "# æŒ‰çœä»½åˆ†ç»„ æŒ‰place_nameæ’åº\n",
    "places_gdf_all.groupby('province')['place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa3655c7c37ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.158720Z",
     "start_time": "2025-07-26T03:25:02.152597Z"
    }
   },
   "outputs": [],
   "source": [
    "# æœ€åä¸€æ­¥æ¸…æ´— ä¸ºäº†æ–¹ä¾¿åŒ¹é…è·¯åï¼ˆå—äº¬è·¯ï¼‰ï¼Œéœ€è¦æŠŠplance_nameä¸­çš„ çœ è‡ªæ²»åŒº å¸‚ åœ°åŒºå»æ‰ï¼Œè€Œprovinceä¸å˜\n",
    "def clean_place_name(name):\n",
    "    # å»æ‰çœã€å¸‚ã€è‡ªæ²»åŒºç­‰åç¼€\n",
    "    suffixes = ['è‡ªæ²»åŒº', 'è‡ªæ²»å·', 'è‡ªæ²»å¿', 'åœ°åŒº', 'çœ', 'å¿', 'åŒº','å¸‚']\n",
    "    for suffix in suffixes:\n",
    "        if name.endswith(suffix):\n",
    "            return name[:-len(suffix)]\n",
    "    return name\n",
    "# åº”ç”¨æ¸…æ´—å‡½æ•°\n",
    "places_gdf_all['cleaned_place_name'] = places_gdf_all['place_name'].apply(clean_place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee9d9730d170b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.412764Z",
     "start_time": "2025-07-26T03:25:02.403875Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf_all.groupby('province')['cleaned_place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6974a315c85eeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.525145Z",
     "start_time": "2025-07-26T03:25:02.519572Z"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ é™¤ provinceä¸ºä¸ç»Ÿè®¡çš„ ä»¥åŠæ¸¯æ¾³å°\n",
    "places_gdf_all = places_gdf_all[~places_gdf_all['province'].isin(['ä¸Šæµ·å¸‚', 'æ¸¯æ¾³å°', 'æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº', 'é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº', 'ä¸ç»Ÿè®¡', 'å°æ¹¾çœ'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf5e86b8d1c30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:02.718650Z",
     "start_time": "2025-07-26T03:25:02.707285Z"
    }
   },
   "outputs": [],
   "source": [
    "places_gdf_all.groupby('province')['cleaned_place_name'].apply(lambda x: ', '.join(sorted(x))).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72743fd443321707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.380646Z",
     "start_time": "2025-07-26T03:25:02.856470Z"
    }
   },
   "outputs": [],
   "source": [
    "# å¯é€‰ ä¿å­˜æ•°æ®\n",
    "places_gdf_all.to_file(output_filename, layer='province_and_places', driver=\"GPKG\", engine='fiona')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c3ce40a8626bb",
   "metadata": {},
   "source": [
    "## ä¸‰ å¼€å§‹åŒ¹é…\n",
    "æ€è€ƒï¼š\n",
    "1. åœ°åæ¥æºå¤šæ ·æ€§ï¼šè·¯åæ ¸å¿ƒè¯æ—¢å¯èƒ½æ˜¯åŸå¸‚ï¼Œä¹Ÿå¯èƒ½æ˜¯çœä»½ã€‚ä¾‹å¦‚â€œå—äº¬è·¯â€å¯¹åº”åŸå¸‚ï¼Œâ€œè¥¿è—ä¸­è·¯â€åˆ™ç›´æ¥å¯¹åº”çœä»½ã€‚\n",
    "2. åç¼€è¯æ±‡ä¸°å¯Œ: ä¸ä»…ä»…æ˜¯â€œè·¯â€ï¼Œè¿˜æœ‰â€œé“â€ã€â€œè¡—â€ã€â€œå··â€ã€â€œå¼„â€ã€â€œæµœâ€ã€â€œæ¡¥â€ç­‰ç­‰ï¼Œä¸€ä¸ªå›ºå®šçš„åç¼€åˆ—è¡¨å¾ˆéš¾åšåˆ°å®Œå…¨è¦†ç›–ã€‚\n",
    "3. å‰åç¼€å¹¶å­˜ï¼šâ€œé™•è¥¿å—è·¯â€æœ‰å‰ç¼€â€œå—â€å’Œåç¼€â€œè·¯â€ï¼›â€œä¸œå®å…´è·¯â€çš„â€œä¸œâ€æ˜¯æ–¹ä½è¯ï¼›è¿™éƒ½å¢åŠ äº†æå–æ ¸å¿ƒè¯çš„éš¾åº¦ã€‚\n",
    "æ ¸å¿ƒè§£æ±ºæªæ–½ï¼šä¸å°è¯•å»â€œçŒœâ€å’Œâ€œå‰¥ç¦»â€è·¯åçš„å‰åç¼€ã€‚ç›¸åï¼Œæˆ‘ä»¬æ‹¿ç€ä¸€ä¸ªæƒå¨çš„ã€åŒ…å«æ‰€æœ‰å¯èƒ½åœ°åï¼ˆåŸå¸‚+çœä»½ï¼‰çš„â€œå­—å…¸â€ ï¼Œå»è·¯åè¿™ä¸ªâ€œé•¿å­—ç¬¦ä¸²â€é‡Œï¼Œå¯»æ‰¾æœ€é•¿ã€æœ€ä¼˜å…ˆçš„åŒ¹é…å­ä¸²ã€‚\n",
    "æ‰€ä»¥æˆ‘å«ï¼š**åŸºäºä¼˜å…ˆçº§çš„æœ€å¤§å­ä¸²åŒ¹é…**ï¼Œä¸ºæ­¤è¿˜éœ€è¦é‡æ–°å¤„ç†åœ°åè¡¨ places_gdf_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b260d387de6cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.464183Z",
     "start_time": "2025-07-26T03:25:04.458376Z"
    }
   },
   "outputs": [],
   "source": [
    "# è®¡ç®—åœ°åé•¿åº¦ï¼Œå¹¶æŒ‰é•¿åº¦é™åºæ’åˆ— åç»­å…ˆåŒ¹é…åœ°åé•¿çš„\n",
    "# å› ä¸ºæ€»è¡¨æ˜¯æŒ‰é•¿åº¦é™åºçš„ï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„åŒ¹é…é¡¹ï¼Œå¿…ç„¶æ˜¯è¿™æ¡è·¯åä¸­å¯èƒ½å­˜åœ¨çš„æœ€é•¿åœ°åã€‚ä¾‹å¦‚ï¼Œå¯¹äºâ€œé™•è¥¿å—è·¯â€ï¼Œå®ƒä¼šå…ˆå°è¯•åŒ¹é…â€œé™•è¥¿â€ï¼Œä¸€æ—¦æˆåŠŸï¼Œå°±ç«‹å³è¿”å›â€œé™•è¥¿â€ï¼Œç»ä¸ä¼šæœ‰æœºä¼šå»åŒ¹é…æ›´çŸ­çš„â€œé™•â€ã€‚\n",
    "\n",
    "places_gdf_all['name_len'] = places_gdf_all['cleaned_place_name'].str.len()\n",
    "master_gazetteer_df = places_gdf_all.sort_values(by='name_len', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40de9a924bd3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.539761Z",
     "start_time": "2025-07-26T03:25:04.524873Z"
    }
   },
   "outputs": [],
   "source": [
    "master_gazetteer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788d0301a593ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.689202Z",
     "start_time": "2025-07-26T03:25:04.685374Z"
    }
   },
   "outputs": [],
   "source": [
    "# é¢„å¤„ç†ï¼šæå–åœ°åå’Œçœä»½ä¸ºåˆ—è¡¨\n",
    "place_names = master_gazetteer_df['cleaned_place_name'].tolist()\n",
    "provinces = master_gazetteer_df['province'].tolist()\n",
    "\n",
    "def find_best_match_fast(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None, None\n",
    "    for place, province in zip(place_names, provinces):\n",
    "        if place in road_name:\n",
    "            return place, province\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87430e592e4788ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.731092Z",
     "start_time": "2025-07-26T03:25:04.727845Z"
    }
   },
   "outputs": [],
   "source": [
    "# # è¿­ä»£åŒ¹é…ï¼ˆæ…¢ï¼‰\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "# # tqdmæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "# match_results = [find_best_match_fast(name) for name in tqdm(roads_gdf['name'], desc=\"åœ°ååŒ¹é…\")]\n",
    "#\n",
    "# match_results_df = pd.DataFrame(match_results, columns=['matched_place', 'province'])\n",
    "# final_gdf = pd.concat([roads_gdf, match_results_df], axis=1)\n",
    "# final_gdf = final_gdf.dropna(subset=['province'])\n",
    "# print(f\"ç²¾ç¡®åŒ¹é…å®Œæˆï¼å…±æ‰¾åˆ° {len(final_gdf)} æ¡ä¸ä¸­å›½åœ°åç›¸å…³çš„é“è·¯ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f6996bbd8c207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:25:04.821565Z",
     "start_time": "2025-07-26T03:25:04.818824Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10041298492ace1",
   "metadata": {},
   "source": [
    "ä¸Šè¿°ç»“æœä¸æ˜¯å¾ˆå¥½ï¼š\n",
    "1.  **è‡ªæˆ‘å‚ç…§å™ªå£°**:\n",
    "    *   `121, G1503ä¸Šæµ·ç»•åŸé«˜é€Ÿ, ä¸Šæµ·, ä¸Šæµ·å¸‚`\n",
    "    *   `939, ä¸Šæµ·ä¸œè·¯, æµ·ä¸œ, é’æµ·çœ`\n",
    "    *   **ç—…å› **: è·¯åä¸­åŒ…å«â€œä¸Šæµ·â€æœ¬èº«ã€‚è¿™äº›é“è·¯å¹¶ä¸æ˜¯ä»¥å¤–åœ°åœ°åå‘½åçš„ï¼Œå®ƒä»¬æ˜¯æˆ‘ä»¬ç ”ç©¶ä¸­çš„â€œå™ªå£°â€ï¼Œå¿…é¡»è¢«å‰”é™¤ã€‚ç¬¬äºŒä¸ªä¾‹å­æ›´ç³Ÿç³•ï¼Œå®ƒæŠŠâ€œä¸Šæµ·ä¸œè·¯â€é”™è¯¯åœ°åŒ¹é…ç»™äº†é’æµ·çš„â€œæµ·ä¸œâ€ï¼Œè¿™æ˜¯ç®—æ³•çš„è¯¯åˆ¤ã€‚\n",
    "\n",
    "2.  **è´ªå©ªçš„å­ä¸²åŒ¹é…**:\n",
    "    *   `376, é‡‘æ²™æ±Ÿè¥¿è·¯, æ±Ÿè¥¿, æ±Ÿè¥¿çœ`\n",
    "    *   **ç—…å› **: è¿™æ˜¯æœ€ç»å…¸ã€æœ€æ£˜æ‰‹çš„é”™è¯¯ã€‚â€œé‡‘æ²™æ±Ÿâ€æ˜¯ä¸€ä¸ªå®Œæ•´çš„åœ°ç†åè¯ï¼ˆä¸€æ¡æ±Ÿï¼‰ï¼Œä½†æˆ‘ä»¬çš„ç®—æ³•å› ä¸ºå­—å…¸é‡Œæœ‰â€œæ±Ÿè¥¿â€ï¼Œå°±è´ªå©ªåœ°æŠŠå®ƒåŒ¹é…ä¸Šäº†ã€‚ç®—æ³•æ²¡æœ‰ç†è§£â€œè¯â€çš„è¾¹ç•Œã€‚\n",
    "\n",
    "3.  **ä¸åˆç†çš„ä¼˜å…ˆé¡ºåº**:\n",
    "    *   `982, æ¾æ±Ÿä¸­å±±ä¸œè·¯, å±±ä¸œ, å±±ä¸œçœ`\n",
    "    *   **ç—…å› **: è¿™æ¡è·¯çš„æ ¸å¿ƒè¯æ˜æ˜¾æ˜¯â€œä¸­å±±â€ï¼Œä½†ç®—æ³•å´åŒ¹é…äº†â€œå±±ä¸œâ€ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºâ€œå±±ä¸œâ€å’Œâ€œä¸­å±±â€é•¿åº¦ä¸€æ ·ï¼Œè€Œåœ¨æˆ‘ä»¬çš„æ’åºä¸­ï¼Œâ€œå±±ä¸œâ€æ’åœ¨äº†â€œä¸­å±±â€å‰é¢ï¼Œå¯¼è‡´äº†é”™è¯¯åŒ¹é…ã€‚ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥æ¾æ±ŸåŒºå¯èƒ½ä¸æ˜¯æˆ‘ä»¬çš„ç ”ç©¶é‡ç‚¹ï¼Œéœ€è¦å‰”é™¤ä¸Šæµ·å¤–å›´åœ°åŒºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff9f30e49f3c45",
   "metadata": {},
   "source": [
    "## ä¼˜åŒ–åŒ¹é…\n",
    "ä¼˜åŒ–æ€è·¯\n",
    "å»æ‰è·¯åå¸¸è§åç¼€ï¼Œå‡å°‘å¹²æ‰°ï¼›\n",
    "ç”¨ Aho-Corasick è‡ªåŠ¨æœºä¸€æ¬¡æ€§æ‰¹é‡åŒ¹é…ï¼Œæå‡æŸ¥æ‰¾æ•ˆç‡ï¼›\n",
    "æ”¶é›†æ‰€æœ‰åŒ¹é…ç»“æœåï¼ŒæŒ‰æœ€é•¿ä¼˜å…ˆã€æœ€æ—©å‡ºç°ä½ç½®æ¥é€‰å–æœ€ä¼˜å€™é€‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbdc2a72f5bb89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:22.119759Z",
     "start_time": "2025-07-26T03:33:22.111085Z"
    }
   },
   "outputs": [],
   "source": [
    "import ahocorasick\n",
    "\n",
    "# 1. æ¸…æ´—è·¯ååç¼€ å­—æ•°å¤šçš„åœ¨å‰ï¼\n",
    "_suffixes = ['è·¯æ¡¥', 'è¾…è·¯', 'åŒ—è·¯', 'ä¸œè·¯', 'å—è·¯', \"è¥¿è·¯\", \"å¤§é“\", 'è·¯', 'é“', 'è¡—', 'å··', 'å¼„', 'æµœ', 'æ¡¥', 'çº¿', 'æ®µ']\n",
    "def _clean_road(road):\n",
    "    # å¦‚æœåªæœ‰ä¸¤ä¸ªå­— åˆ™ä¸å»æ‰åç¼€\n",
    "    if len(road) <= 2:\n",
    "        return road\n",
    "     # éå†æ‰€æœ‰åç¼€ï¼Œæ‰¾åˆ°åŒ¹é…çš„åç¼€å¹¶å»æ‰\n",
    "     # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾åç¼€åˆ—è¡¨æ˜¯æŒ‰é•¿åº¦é™åºæ’åˆ—çš„ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿æœ€é•¿çš„åç¼€ä¼˜å…ˆåŒ¹é…\n",
    "     # å¦‚æœæœ‰å¤šä¸ªåç¼€åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç»“æœ\n",
    "    for s in _suffixes:\n",
    "        if road.endswith(s):\n",
    "            return road[:-len(s)]\n",
    "    return road\n",
    "\n",
    "# é’ˆå¯¹è·¯åçš„æœ€å°åŒ¹é…é•¿åº¦\n",
    "MIN_MATCH_LEN = 2\n",
    "\n",
    "# æ„å»º Aho-Corasick è‡ªåŠ¨æœºï¼Œåªæ·»åŠ é•¿åº¦ â‰¥ MIN_MATCH_LEN çš„åœ°å\n",
    "A = ahocorasick.Automaton()\n",
    "\n",
    "for name, prov in zip(place_names, provinces):\n",
    "    if len(name) >= MIN_MATCH_LEN:\n",
    "        A.add_word(name, (name, prov))\n",
    "A.make_automaton()\n",
    "\n",
    "# 3. æœ€ä¼˜åŒ¹é…å‡½æ•°ï¼šæœ€é•¿ä¼˜å…ˆã€æœ€æ—©å‡ºç°\n",
    "def find_best_match_aho(road):\n",
    "    if not isinstance(road, str):\n",
    "        return None, None\n",
    "\n",
    "    # è¿”å›æ¸…ç†çš„æ–‡æœ¬\n",
    "    text = _clean_road(road)\n",
    "    best = None  # (place, prov, length, pos)\n",
    "\n",
    "    for end, (place, prov) in A.iter(text):\n",
    "        length = len(place)\n",
    "\n",
    "        start = end - len(place) + 1\n",
    "        length = len(place)\n",
    "        if not best or length > best[2] or (length == best[2] and start < best[3]):\n",
    "            best = (place, prov, length, start)\n",
    "    return (best[0], best[1]) if best else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877fbd3e3908130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:23.111704Z",
     "start_time": "2025-07-26T03:33:23.017288Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 1. æ‰¹é‡åŒ¹é…\n",
    "results = [\n",
    "    find_best_match_aho(name)\n",
    "    for name in tqdm(dissolved_roads_in_aoi['name'], desc=\"åœ°ååŒ¹é…\")\n",
    "]\n",
    "\n",
    "# 2. è½¬ä¸º DataFrame\n",
    "match_df = pd.DataFrame(results, columns=['matched_place', 'province'])\n",
    "\n",
    "\n",
    "# æ„å»º clean->åŸå§‹ place_name æ˜ å°„\n",
    "mapping = dict(zip(master_gazetteer_df['cleaned_place_name'], master_gazetteer_df['place_name']))\n",
    "\n",
    "# åœ¨ match_df ä¸­æ–°å¢åŸå§‹åœ°ååˆ—\n",
    "match_df['original_place_name'] = match_df['matched_place'].map(mapping)\n",
    "\n",
    "# ç„¶åå†åˆå¹¶æœ€ç»ˆç»“æœ\n",
    "final_gdf = pd.concat([dissolved_roads_in_aoi.reset_index(drop=True), match_df], axis=1)\n",
    "final_gdf = final_gdf.dropna(subset=['province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04d3ab3e0c3507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:23.542837Z",
     "start_time": "2025-07-26T03:33:23.533843Z"
    }
   },
   "outputs": [],
   "source": [
    "final_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bc7ce8b6617f5",
   "metadata": {},
   "source": [
    "å¤§å¤šæ•°éƒ½æ˜¯å‡†ç¡®çš„ï¼šè€Œä¸”æœç´¢ä¹‹åæ‰å‘ç°ï¼š**â€œé•¿å®â€ç¡®å®æ˜¯å››å·çœçš„ä¸€ä¸ªåœ°å**ï¼Œå‡†ç¡®æ¥è¯´æ˜¯**å››å·çœå®œå®¾å¸‚ä¸‹è¾–çš„â€œé•¿å®å¿â€**ï¼Œå¹¶éâ€œé•¿å®å¸‚â€ã€‚\n",
    "\n",
    "> é•¿å®å¿ä½äºå››å·ç›†åœ°å—ç¼˜ï¼Œåœ°å¤„å®œå®¾å¸‚è…¹åœ°ï¼Œå› å†å²ä¸Šâ€œåœ°åŠ¿è¾¹è¿œå®é™â€æˆ–â€œå¸Œå†€æ°‘æ—å’Œç¦â€è€Œå¾—åï¼Œç´ æœ‰â€œç«¹å­ä¹‹ä¹¡â€çš„ç¾èª‰ã€‚æ­¤å¤–ï¼Œ**ä¸Šæµ·çš„é•¿å®åŒº**å’Œ**é•¿å®è·¯**æ­£æ˜¯å¾—åäºå››å·çš„è¿™ä¸ªâ€œé•¿å®å¿â€ã€‚\n",
    "\n",
    "è¿™é‡Œè¡¥å……ä¸€äº›æœªæˆåŠŸåŒ¹é…çš„æ•°æ®ï¼Œæ¯”å¦‚ï¼š\n",
    "å¤©å±±è¥¿è·¯,\"LINESTRING (121.34698 31.21907, 121.34755 31.21902, 121.34813 31.21898)\",å±±è¥¿,å±±è¥¿çœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671a11dd659ca6f",
   "metadata": {},
   "source": [
    "# ç©ºé—´åˆ†æä¸èšç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ea994283a1f79",
   "metadata": {},
   "source": [
    "##ã€€1. æŒ‰çœä»½èšåˆä¸ºâ€œä»£è¡¨ç‚¹â€æˆ–â€œä¸­å¿ƒçº¿â€\n",
    "æƒ³åšâ€œä¸­å›½åœ°å›¾ç¼©å½±â€ï¼Œä¸­è§‚ç©ºé—´åˆ†å¸ƒ\n",
    "\n",
    "ï¼ã€€æ¯çœä»½çš„â€œæ‰€æœ‰é“è·¯â€åˆå¹¶æˆä¸€ä¸ªMultiLineStringï¼Œæ±‚å…¶ geometry.centroid å¾—åˆ°â€œä»£è¡¨ç‚¹â€ã€‚\n",
    "ï¼ã€€è¿˜å¯ä»¥æ±‚â€œä»£è¡¨çº¿/çœä»½èšåˆçº¿æ¡â€ï¼Œä¹Ÿå°±æ˜¯æ¯çœæ‰€æœ‰å‘½åè·¯æ®µçš„è”åˆå›¾å½¢ï¼ˆæ¯”å¦‚ç”¨äºå¯è§†åŒ–æè¾¹/åŒºåŸŸèšåˆï¼‰ã€‚\n",
    "ï¼ã€€é™¤å‡ ä½•èšåˆå¤–ï¼Œå¯ä»¥ç»Ÿè®¡æ¯çœä»½åŒ¹é…è·¯æ®µæ•°é‡ï¼Œå¹¶ä¸€èµ·èšåˆè¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0580210a5607a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:25.447145Z",
     "start_time": "2025-07-26T03:33:25.339422Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.ops import unary_union\n",
    "\n",
    "# æŒ‰çœä»½åˆ†ç»„ï¼Œåˆå¹¶æ‰€æœ‰é“è·¯å‡ ä½•\n",
    "province_group = final_gdf.groupby('province').apply(\n",
    "    lambda df: pd.Series({\n",
    "        'geometry': unary_union(df['geometry']),\n",
    "        'road_count': df['name'].count(),  # æ”¹åä¸º road_count\n",
    "        'road_names': ', '.join(sorted(df['name'].unique())),  # ä¿ç•™æ‰€æœ‰é“è·¯åç§°\n",
    "        'matched_places': ', '.join(sorted(set(df['matched_place'])))  # æ”¹åä¸º matched_places\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# è®¡ç®—æ¯çœçš„è´¨å¿ƒ\n",
    "province_group['centroid'] = province_group['geometry'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b1bf6881c6c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:25.988106Z",
     "start_time": "2025-07-26T03:33:25.978004Z"
    }
   },
   "outputs": [],
   "source": [
    "province_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ba060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:26.433510Z",
     "start_time": "2025-07-26T03:33:26.431786Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac1bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:27.008726Z",
     "start_time": "2025-07-26T03:33:26.916397Z"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ†åˆ«ä¿å­˜çº¿å’Œç‚¹\n",
    "province_group[['province', 'geometry', 'road_count', 'road_names']].to_file(output_filename, layer='province_roads', driver=\"GPKG\", engine='fiona',crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_group[['province', 'centroid', 'road_count', 'road_names']].set_geometry('centroid').to_file(output_filename, layer='province_centroids', driver=\"GPKG\", engine='fiona',crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0c92482c47cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:29.757353Z",
     "start_time": "2025-07-26T03:33:27.565689Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ›´å¥½çš„æ˜¾ç¤ºå‚æ•°\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# åˆ›å»ºæ›´å¤§çš„å›¾å½¢\n",
    "fig, ax = plt.subplots(figsize=(18, 14))\n",
    "\n",
    "# è®¾ç½®èƒŒæ™¯è‰²\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "\n",
    "# 1. ç»˜åˆ¶èšåˆçº¿ï¼ˆåº•å±‚ï¼‰\n",
    "# 1. ä¸ºæ¯ä¸ªçœä»½åˆ†é…ä¸åŒé¢œè‰²\n",
    "n_provinces = len(province_group)\n",
    "# ä½¿ç”¨tab20é¢œè‰²æ˜ å°„ï¼Œå®ƒæœ‰20ç§ä¸åŒçš„é¢œè‰²\n",
    "\n",
    "\n",
    "colors = cm.tab20(np.linspace(0, 1, n_provinces))\n",
    "\n",
    "# 2. é€ä¸ªç»˜åˆ¶æ¯ä¸ªçœä»½çš„èšåˆçº¿\n",
    "for idx, (_, row) in enumerate(province_group.iterrows()):\n",
    "    # åˆ›å»ºå•ä¸ªçœä»½çš„GeoDataFrame\n",
    "    single_province = gpd.GeoDataFrame([row], crs=province_group.crs if hasattr(province_group, 'crs') else None)\n",
    "    \n",
    "    # ç»˜åˆ¶è¯¥çœä»½çš„çº¿æ¡\n",
    "    single_province.plot(ax=ax, \n",
    "                        color=colors[idx], \n",
    "                        linewidth=2.5, \n",
    "                        alpha=0.8,\n",
    "                        label=row['province'], \n",
    "                        zorder=1)\n",
    "\n",
    "# 2. ç»˜åˆ¶ä»£è¡¨ç‚¹ï¼ˆé¡¶å±‚ï¼‰- ä½¿ç”¨æ›´é†’ç›®çš„çº¢è‰²ï¼Œå¢åŠ è¾¹æ¡†\n",
    "# sizes = province_group['name'] * 15 + 50  # åŸºç¡€å¤§å°50ï¼ŒæŒ‰é“è·¯æ•°é‡è°ƒæ•´\n",
    "\n",
    "province_group.set_geometry('centroid').plot(ax=ax, \n",
    "                                            color='#F24236', \n",
    "                                            markersize=80,\n",
    "                                            edgecolor='white',\n",
    "                                            linewidth=3,\n",
    "                                            label='ä»£è¡¨ç‚¹', \n",
    "                                            zorder=3)\n",
    "\n",
    "# 3. æ ‡æ³¨çœä»½åç§°ï¼ˆæœ€é¡¶å±‚ï¼‰- æ”¹å–„æ–‡å­—æ ·å¼\n",
    "for idx, row in province_group.iterrows():\n",
    "    x, y = row['centroid'].x, row['centroid'].y\n",
    "    \n",
    "    # æ·»åŠ æ–‡å­—èƒŒæ™¯æ¡†\n",
    "    ax.text(x, y, row['province'], \n",
    "           fontsize=11, \n",
    "           color='#2c3e50',\n",
    "           ha='center', \n",
    "           va='center',\n",
    "           weight='bold',\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                    facecolor='white', \n",
    "                    edgecolor='#bdc3c7',\n",
    "                    alpha=0.9),\n",
    "           zorder=4)\n",
    "\n",
    "# 4. ç¾åŒ–å›¾è¡¨\n",
    "ax.set_title(\"ä¸Šæµ·åœ°åè·¯ç½‘ç©ºé—´åˆ†å¸ƒåˆ†æ\\nå„çœä»½é“è·¯èšåˆä¸ä»£è¡¨ç‚¹ä½ç½®\", \n",
    "            fontsize=16, \n",
    "            fontweight='bold', \n",
    "            color='#2c3e50',\n",
    "            pad=20)\n",
    "\n",
    "# è®¾ç½®åæ ‡è½´\n",
    "ax.set_xlabel('ç»åº¦', fontsize=12, color='#34495e')\n",
    "ax.set_ylabel('çº¬åº¦', fontsize=12, color='#34495e')\n",
    "\n",
    "# ç¾åŒ–ç½‘æ ¼\n",
    "ax.grid(True, alpha=0.3, color='#bdc3c7', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# ç¾åŒ–å›¾ä¾‹\n",
    "legend = ax.legend(loc='upper right', \n",
    "                  frameon=True, \n",
    "                  fancybox=True, \n",
    "                  shadow=True,\n",
    "                  fontsize=11)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# è®¾ç½®åæ ‡è½´åˆ»åº¦é¢œè‰²\n",
    "ax.tick_params(colors='#34495e', labelsize=10)\n",
    "\n",
    "# ç§»é™¤ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡†\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('#bdc3c7')\n",
    "ax.spines['bottom'].set_color('#bdc3c7')\n",
    "\n",
    "# è°ƒæ•´å¸ƒå±€\n",
    "plt.tight_layout()\n",
    "\n",
    "# æ˜¾ç¤ºå›¾è¡¨\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c115456745e19de",
   "metadata": {},
   "source": [
    "## 4. ç©ºé—´èšç±»åˆ†æ\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬æ¥åˆ†ææ¯ä¸ªçœä»½çš„é“è·¯åœ¨ä¸Šæµ·çš„ç©ºé—´åˆ†å¸ƒæ¨¡å¼ï¼š\n",
    "- ä½¿ç”¨KMeansèšç±»åˆ†ææ¯çœé“è·¯çš„æ ¸å¿ƒåˆ†å¸ƒåŒºåŸŸ\n",
    "- ä½¿ç”¨DBSCANè¯†åˆ«é«˜å¯†åº¦èšé›†åŒº\n",
    "- åˆ†æå“ªäº›çœä»½å‘ˆç°\"å¤šæ ¸å¿ƒåˆ†å¸ƒ\"ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6fef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:34.911367Z",
     "start_time": "2025-07-26T03:33:34.879099Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.1 å‡†å¤‡èšç±»æ•°æ®ï¼šè®¡ç®—æ¯æ¡é“è·¯çš„è´¨å¿ƒ\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# ä¸ºæ¯æ¡é“è·¯è®¡ç®—è´¨å¿ƒåæ ‡\n",
    "final_gdf['centroid'] = final_gdf['geometry'].centroid\n",
    "final_gdf['lon'] = final_gdf['centroid'].x\n",
    "final_gdf['lat'] = final_gdf['centroid'].y\n",
    "\n",
    "print(\"âœ… é“è·¯è´¨å¿ƒè®¡ç®—å®Œæˆ\")\n",
    "print(f\"æ€»è®¡ {len(final_gdf)} æ¡é“è·¯å¾…åˆ†æ\")\n",
    "\n",
    "# æŒ‰çœä»½ç»Ÿè®¡é“è·¯æ•°é‡ï¼Œé€‰æ‹©é“è·¯æ•°é‡è¾ƒå¤šçš„çœä»½è¿›è¡Œèšç±»\n",
    "province_stats = final_gdf['province'].value_counts()\n",
    "print(\"\\nğŸ“Š å„çœä»½é“è·¯æ•°é‡ç»Ÿè®¡ï¼š\")\n",
    "print(province_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0cd54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:35.684918Z",
     "start_time": "2025-07-26T03:33:35.678879Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.2 KMeansèšç±»åˆ†æå‡½æ•°\n",
    "def analyze_province_clusters_kmeans(province_name, n_clusters=3, min_roads=5):\n",
    "    \"\"\"\n",
    "    å¯¹æŒ‡å®šçœä»½çš„é“è·¯è¿›è¡ŒKMeansèšç±»åˆ†æ\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - province_name: çœä»½åç§°\n",
    "    - n_clusters: èšç±»æ•°é‡\n",
    "    - min_roads: æœ€å°‘é“è·¯æ•°é‡é˜ˆå€¼\n",
    "    \"\"\"\n",
    "    \n",
    "    # ç­›é€‰è¯¥çœä»½çš„é“è·¯\n",
    "    province_roads = final_gdf[final_gdf['province'] == province_name].copy()\n",
    "    \n",
    "    if len(province_roads) < min_roads:\n",
    "        print(f\"âš ï¸ {province_name} é“è·¯æ•°é‡ä¸è¶³ ({len(province_roads)} < {min_roads})ï¼Œè·³è¿‡èšç±»\")\n",
    "        return None\n",
    "    \n",
    "    # æå–åæ ‡\n",
    "    coords = province_roads[['lon', 'lat']].values\n",
    "    \n",
    "    # æ ‡å‡†åŒ–åæ ‡ï¼ˆé‡è¦ï¼šé¿å…ç»çº¬åº¦å°ºåº¦å·®å¼‚ï¼‰\n",
    "    scaler = StandardScaler()\n",
    "    coords_scaled = scaler.fit_transform(coords)\n",
    "    \n",
    "    # KMeansèšç±»\n",
    "    kmeans = KMeans(n_clusters=min(n_clusters, len(province_roads)), random_state=42)\n",
    "    province_roads.loc[:, 'cluster'] = kmeans.fit_predict(coords_scaled)\n",
    "    \n",
    "    # è®¡ç®—èšç±»ä¸­å¿ƒï¼ˆåŸå§‹åæ ‡ï¼‰\n",
    "    cluster_centers = []\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        cluster_coords = coords[province_roads['cluster'] == i]\n",
    "        center_lon = cluster_coords[:, 0].mean()\n",
    "        center_lat = cluster_coords[:, 1].mean()\n",
    "        cluster_size = len(cluster_coords)\n",
    "        cluster_centers.append({\n",
    "            'cluster_id': i,\n",
    "            'center_lon': center_lon,\n",
    "            'center_lat': center_lat,\n",
    "            'road_count': cluster_size,\n",
    "            'roads': province_roads[province_roads['cluster'] == i]['name'].tolist()\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'province': province_name,\n",
    "        'total_roads': len(province_roads),\n",
    "        'n_clusters': kmeans.n_clusters,\n",
    "        'cluster_centers': cluster_centers,\n",
    "        'roads_with_clusters': province_roads\n",
    "    }\n",
    "\n",
    "print(\"âœ… KMeansèšç±»åˆ†æå‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2abcd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:36.581569Z",
     "start_time": "2025-07-26T03:33:36.575014Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.3 DBSCANèšç±»åˆ†æå‡½æ•°\n",
    "def analyze_province_clusters_dbscan(province_name, eps=0.01, min_samples=2, min_roads=5):\n",
    "    \"\"\"\n",
    "    å¯¹æŒ‡å®šçœä»½çš„é“è·¯è¿›è¡ŒDBSCANèšç±»åˆ†æ\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - province_name: çœä»½åç§°\n",
    "    - eps: DBSCANçš„é‚»åŸŸåŠå¾„å‚æ•°ï¼ˆç»çº¬åº¦å•ä½ï¼Œçº¦1kmâ‰ˆ0.01åº¦ï¼‰\n",
    "    - min_samples: å½¢æˆèšç±»çš„æœ€å°æ ·æœ¬æ•°\n",
    "    - min_roads: æœ€å°‘é“è·¯æ•°é‡é˜ˆå€¼\n",
    "    \"\"\"\n",
    "    \n",
    "    # ç­›é€‰è¯¥çœä»½çš„é“è·¯\n",
    "    province_roads = final_gdf[final_gdf['province'] == province_name].copy()\n",
    "    \n",
    "    if len(province_roads) < min_roads:\n",
    "        print(f\"âš ï¸ {province_name} é“è·¯æ•°é‡ä¸è¶³ ({len(province_roads)} < {min_roads})ï¼Œè·³è¿‡èšç±»\")\n",
    "        return None\n",
    "    \n",
    "    # æå–åæ ‡\n",
    "    coords = province_roads[['lon', 'lat']].values\n",
    "    \n",
    "    # DBSCANèšç±»ï¼ˆä¸éœ€è¦æ ‡å‡†åŒ–ï¼Œç›´æ¥ä½¿ç”¨ç»çº¬åº¦ï¼‰\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    province_roads.loc[:, 'cluster'] = dbscan.fit_predict(coords)\n",
    "    \n",
    "    # ç»Ÿè®¡èšç±»ç»“æœ\n",
    "    unique_clusters = set(province_roads['cluster'])\n",
    "    noise_count = sum(province_roads['cluster'] == -1)  # -1è¡¨ç¤ºå™ªå£°ç‚¹\n",
    "    \n",
    "    # è®¡ç®—æœ‰æ•ˆèšç±»ä¸­å¿ƒ\n",
    "    cluster_centers = []\n",
    "    for cluster_id in unique_clusters:\n",
    "        if cluster_id == -1:  # è·³è¿‡å™ªå£°ç‚¹\n",
    "            continue\n",
    "            \n",
    "        cluster_coords = coords[province_roads['cluster'] == cluster_id]\n",
    "        center_lon = cluster_coords[:, 0].mean()\n",
    "        center_lat = cluster_coords[:, 1].mean()\n",
    "        cluster_size = len(cluster_coords)\n",
    "        \n",
    "        cluster_centers.append({\n",
    "            'cluster_id': cluster_id,\n",
    "            'center_lon': center_lon,\n",
    "            'center_lat': center_lat,\n",
    "            'road_count': cluster_size,\n",
    "            'roads': province_roads[province_roads['cluster'] == cluster_id]['name'].tolist()\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'province': province_name,\n",
    "        'total_roads': len(province_roads),\n",
    "        'n_clusters': len(cluster_centers),\n",
    "        'noise_points': noise_count,\n",
    "        'cluster_centers': cluster_centers,\n",
    "        'roads_with_clusters': province_roads\n",
    "    }\n",
    "\n",
    "print(\"âœ… DBSCANèšç±»åˆ†æå‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eae019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:33:37.532523Z",
     "start_time": "2025-07-26T03:33:37.029406Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.4 æ‰¹é‡æ‰§è¡Œèšç±»åˆ†æ\n",
    "# é€‰æ‹©é“è·¯æ•°é‡ >= 8 çš„çœä»½è¿›è¡Œåˆ†æ\n",
    "target_provinces = province_stats[province_stats >= 8].index.tolist()\n",
    "\n",
    "print(f\"ğŸ¯ ç›®æ ‡çœä»½ï¼š{target_provinces}\")\n",
    "print(f\"æ€»è®¡ {len(target_provinces)} ä¸ªçœä»½å°†è¿›è¡Œèšç±»åˆ†æ\\n\")\n",
    "\n",
    "# å­˜å‚¨èšç±»ç»“æœ\n",
    "kmeans_results = {}\n",
    "dbscan_results = {}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"å¼€å§‹ KMeans èšç±»åˆ†æ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"\\nğŸ” åˆ†æ {province}...\")\n",
    "    \n",
    "    # KMeansåˆ†æ\n",
    "    kmeans_result = analyze_province_clusters_kmeans(province, n_clusters=1)\n",
    "    if kmeans_result:\n",
    "        kmeans_results[province] = kmeans_result\n",
    "        print(f\"âœ… KMeanså®Œæˆ: {kmeans_result['n_clusters']} ä¸ªèšç±»ä¸­å¿ƒ\")\n",
    "        \n",
    "        # æ˜¾ç¤ºèšç±»è¯¦æƒ…\n",
    "        for center in kmeans_result['cluster_centers']:\n",
    "            print(f\"   èšç±» {center['cluster_id']}: {center['road_count']} æ¡é“è·¯\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"å¼€å§‹ DBSCAN èšç±»åˆ†æ...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"\\nğŸ” åˆ†æ {province}...\")\n",
    "    \n",
    "    # DBSCANåˆ†æ\n",
    "    dbscan_result = analyze_province_clusters_dbscan(province, eps=0.01, min_samples=2)\n",
    "    if dbscan_result:\n",
    "        dbscan_results[province] = dbscan_result\n",
    "        print(f\"âœ… DBSCANå®Œæˆ: {dbscan_result['n_clusters']} ä¸ªèšç±»ä¸­å¿ƒ, {dbscan_result['noise_points']} ä¸ªå™ªå£°ç‚¹\")\n",
    "        \n",
    "        # æ˜¾ç¤ºèšç±»è¯¦æƒ…\n",
    "        for center in dbscan_result['cluster_centers']:\n",
    "            print(f\"   èšç±» {center['cluster_id']}: {center['road_count']} æ¡é“è·¯\")\n",
    "\n",
    "print(\"\\nğŸ‰ èšç±»åˆ†æå…¨éƒ¨å®Œæˆï¼\")\n",
    "print(f\"KMeansç»“æœ: {len(kmeans_results)} ä¸ªçœä»½\")\n",
    "print(f\"DBSCANç»“æœ: {len(dbscan_results)} ä¸ªçœä»½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "province_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a64bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237af8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:39:59.295156Z",
     "start_time": "2025-07-26T03:39:45.906278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.5 å¯è§†åŒ–èšç±»ç»“æœ\n",
    "def plot_province_clusters(province_name, method='both', figsize=(16, 6), show_plot=True):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–ç‰¹å®šçœä»½çš„èšç±»ç»“æœ\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - province_name: çœä»½åç§°\n",
    "    - method: æ˜¾ç¤ºæ–¹æ³• ('kmeans', 'dbscan', 'both')\n",
    "    - figsize: å›¾å½¢å¤§å°\n",
    "    - show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾å½¢ï¼ˆä¿å­˜æ—¶è®¾ä¸ºFalseï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'both':\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes = [ax1, ax2]\n",
    "        methods = ['kmeans', 'dbscan']\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        axes = [ax]\n",
    "        methods = [method]\n",
    "\n",
    "    # æ„é€ è¦æ˜¾ç¤ºçš„ä¿¡æ¯ - ç§»åˆ°æ ‡é¢˜ä¸­\n",
    "    road_count = province_stats[province_name]\n",
    "    sample_roads = ', '.join(final_gdf[final_gdf['province'] == province_name]['name'].unique()[:5])\n",
    "    if len(final_gdf[final_gdf['province'] == province_name]['name'].unique()) > 5:\n",
    "        sample_roads += \"...\"\n",
    "\n",
    "    for i, current_method in enumerate(methods):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # å…ˆç»˜åˆ¶ä¸Šæµ·è¡Œæ”¿åŒºåˆ’åº•å›¾ï¼ˆåªè¦è¾¹ç•Œçº¿ï¼Œä¸å¡«å……ï¼‰\n",
    "        aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "        aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0, label='ä¸Šæµ·è¡Œæ”¿åŒºåˆ’')\n",
    "        \n",
    "        # ç»˜åˆ¶åº•å›¾é“è·¯ é¢œè‰²æ·¡ä¸€ç‚¹\n",
    "        dissolved_roads_in_aoi.plot(ax=ax, color='lightgray', linewidth=0.5, alpha=0.5, zorder=0, label='æ‰€æœ‰é“è·¯ï¼ˆåˆå¹¶åï¼‰')\n",
    "        \n",
    "        \n",
    "        # ç»˜åˆ¶å¯¹åº”çš„é“è·¯\n",
    "        roads = final_gdf[final_gdf['province'] == province_name].copy().geometry\n",
    "        roads.plot(ax=ax, color='black', linewidth=1.5, alpha=1, zorder=1, label='æ‰€å±é“è·¯')\n",
    "\n",
    "\n",
    "        if current_method == 'kmeans' and province_name in kmeans_results:\n",
    "            result = kmeans_results[province_name]\n",
    "            roads_data = result['roads_with_clusters']\n",
    "            title = f\"{province_name} - KMeansèšç±» ({result['n_clusters']} ä¸ªèšç±»)\\né“è·¯æ•°é‡: {road_count} æ¡ | ç¤ºä¾‹: {sample_roads}\"\n",
    "\n",
    "            \n",
    "        elif current_method == 'dbscan' and province_name in dbscan_results:\n",
    "            result = dbscan_results[province_name]\n",
    "            roads_data = result['roads_with_clusters']\n",
    "            title = f\"{province_name} - DBSCANèšç±» ({result['n_clusters']} ä¸ªèšç±»)\\né“è·¯æ•°é‡: {road_count} æ¡ | ç¤ºä¾‹: {sample_roads}\"\n",
    "\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"æ—  {current_method.upper()} èšç±»ç»“æœ\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{province_name} - {current_method.upper()}\")\n",
    "            continue\n",
    "        \n",
    "        # ç»˜åˆ¶é“è·¯ç‚¹ï¼ŒæŒ‰èšç±»ç€è‰²\n",
    "        unique_clusters = roads_data['cluster'].unique()\n",
    "        colors = cm.tab10(np.linspace(0, 1, len(unique_clusters)))\n",
    "        \n",
    "        for j, cluster_id in enumerate(unique_clusters):\n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            \n",
    "            if cluster_id == -1:  # DBSCANçš„å™ªå£°ç‚¹\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c='green', s=10, alpha=0.8, label='å™ªå£°ç‚¹')\n",
    "            else:\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c=[colors[j]], s=15, alpha=1, label=f'èšç±» {cluster_id}')\n",
    "        \n",
    "        # ç»˜åˆ¶èšç±»ä¸­å¿ƒ\n",
    "        for center in result['cluster_centers']:\n",
    "            ax.scatter(center['center_lon'], center['center_lat'], \n",
    "                      c='red', s=50, marker='*',\n",
    "                      label='èšç±»ä¸­å¿ƒ' if center['cluster_id'] == result['cluster_centers'][0]['cluster_id'] else \"\")\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('ç»åº¦')\n",
    "        ax.set_ylabel('çº¬åº¦')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "     # åªæœ‰åœ¨show_plot=Trueæ—¶æ‰æ˜¾ç¤ºå›¾å½¢\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "        \n",
    "    return fig  # è¿”å›å›¾å½¢å¯¹è±¡\n",
    "\n",
    "# å¯è§†åŒ–å‡ ä¸ªä»£è¡¨æ€§çœä»½\n",
    "representative_provinces = ['æ±Ÿè‹çœ', 'æµ™æ±Ÿçœ', 'å±±ä¸œçœ', 'å‰æ—çœ']\n",
    "\n",
    "for province in representative_provinces:\n",
    "    if province in target_provinces:\n",
    "        print(f\"\\nğŸ“Š {province} èšç±»ç»“æœå¯è§†åŒ–:\")\n",
    "        plot_province_clusters(province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12f2c5d473980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ‰€æœ‰çœä»½çš„å›¾æ ‡å¯è§†åŒ–åˆ°æ–‡ä»¶å¤¹\n",
    "from pathlib import Path\n",
    "output_folder = 'image/province_clusters_visualization'\n",
    "\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"ğŸ“Š æ­£åœ¨ä¿å­˜ {province} çš„èšç±»å¯è§†åŒ–å›¾...\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºå›¾å½¢ï¼Œä¸æ˜¾ç¤º\n",
    "        fig = plot_province_clusters(province, method='both', figsize=(16, 6), show_plot=False)\n",
    "        \n",
    "        # ä¿å­˜å›¾å½¢\n",
    "        save_path = Path(output_folder) / f\"{province}_clusters.png\"\n",
    "        fig.savefig(save_path, \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300,\n",
    "                    facecolor='white',\n",
    "                    edgecolor='none')\n",
    "        \n",
    "        print(f\"   âœ… å·²ä¿å­˜: {save_path}\")\n",
    "        \n",
    "        # å…³é—­å›¾å½¢é‡Šæ”¾å†…å­˜\n",
    "        plt.close(fig)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ä¿å­˜å¤±è´¥: {e}\")\n",
    "        # ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿå…³é—­å›¾å½¢\n",
    "        plt.close('all')\n",
    "\n",
    "print(f\"âœ… æ‰€æœ‰èšç±»å¯è§†åŒ–å›¾å·²ä¿å­˜åˆ° '{output_folder}' æ–‡ä»¶å¤¹\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02d5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:31:58.932959Z",
     "start_time": "2025-07-26T03:31:58.803693Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.6 èšç±»ç»“æœåˆ†æä¸æ€»ç»“\n",
    "def analyze_clustering_patterns():\n",
    "    \"\"\"\n",
    "    åˆ†æå„çœä»½çš„èšç±»æ¨¡å¼ï¼Œè¯†åˆ«å¤šæ ¸å¿ƒåˆ†å¸ƒç‰¹å¾\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ” èšç±»æ¨¡å¼åˆ†ææŠ¥å‘Š\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ†æKMeansç»“æœ\n",
    "    print(\"\\nğŸ“Š KMeansèšç±»åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for province, result in kmeans_results.items():\n",
    "        n_clusters = result['n_clusters']\n",
    "        total_roads = result['total_roads']\n",
    "        \n",
    "        # è®¡ç®—èšç±»å¹³è¡¡åº¦ï¼ˆå„èšç±»å¤§å°çš„æ ‡å‡†å·®ï¼‰\n",
    "        cluster_sizes = [center['road_count'] for center in result['cluster_centers']]\n",
    "        balance_score = np.std(cluster_sizes) / np.mean(cluster_sizes) if len(cluster_sizes) > 1 else 0\n",
    "        \n",
    "        distribution_type = \"å¤šæ ¸å¿ƒåˆ†å¸ƒ\" if n_clusters >= 3 and balance_score < 0.5 else \\\n",
    "                           \"åŒæ ¸å¿ƒåˆ†å¸ƒ\" if n_clusters == 2 else \"å•æ ¸å¿ƒåˆ†å¸ƒ\"\n",
    "        \n",
    "        print(f\"{province:8s}: {total_roads:2d}æ¡é“è·¯ â†’ {n_clusters}ä¸ªèšç±» ({distribution_type})\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæ¯ä¸ªèšç±»çš„è¯¦ç»†ä¿¡æ¯\n",
    "        for center in result['cluster_centers']:\n",
    "            sample_roads = center['roads']\n",
    "            roads_preview = ', '.join(sample_roads) + ('...' if len(center['roads']) > 3 else '')\n",
    "            print(f\"         èšç±»{center['cluster_id']}: {center['road_count']}æ¡ - {roads_preview}\")\n",
    "    \n",
    "    # åˆ†æDBSCANç»“æœ\n",
    "    print(f\"\\nğŸ“Š DBSCANèšç±»åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for province, result in dbscan_results.items():\n",
    "        n_clusters = result['n_clusters']\n",
    "        total_roads = result['total_roads']\n",
    "        noise_points = result['noise_points']\n",
    "        \n",
    "        noise_ratio = noise_points / total_roads * 100\n",
    "        \n",
    "        density_type = \"é«˜å¯†åº¦èšé›†\" if noise_ratio < 20 else \\\n",
    "                      \"ä¸­ç­‰å¯†åº¦\" if noise_ratio < 50 else \"åˆ†æ•£åˆ†å¸ƒ\"\n",
    "        \n",
    "        print(f\"{province:8s}: {total_roads:2d}æ¡é“è·¯ â†’ {n_clusters}ä¸ªèšç±» + {noise_points}å™ªå£°ç‚¹ ({density_type})\")\n",
    "        \n",
    "        # æ˜¾ç¤ºæœ‰æ•ˆèšç±»ä¿¡æ¯\n",
    "        for center in result['cluster_centers']:\n",
    "            sample_roads = center['roads']\n",
    "            roads_preview = ', '.join(sample_roads) + ('...' if len(center['roads']) > 3 else '')\n",
    "            print(f\"         èšç±»{center['cluster_id']}: {center['road_count']}æ¡ - {roads_preview}\")\n",
    "\n",
    "# æ‰§è¡Œèšç±»æ¨¡å¼åˆ†æ\n",
    "analyze_clustering_patterns()\n",
    "\n",
    "# 4.7 ä¿å­˜èšç±»ç»“æœ\n",
    "print(f\"\\nğŸ’¾ ä¿å­˜èšç±»åˆ†æç»“æœ...\")\n",
    "\n",
    "# ä¿å­˜èšç±»ä¸­å¿ƒä¸ºåœ°ç†æ•°æ®\n",
    "all_cluster_centers = []\n",
    "\n",
    "for province, result in kmeans_results.items():\n",
    "    for center in result['cluster_centers']:\n",
    "        all_cluster_centers.append({\n",
    "            'province': province,\n",
    "            'method': 'KMeans',\n",
    "            'cluster_id': center['cluster_id'],\n",
    "            'road_count': center['road_count'],\n",
    "            'center_lon': center['center_lon'],\n",
    "            'center_lat': center['center_lat'],\n",
    "            'geometry': gpd.points_from_xy([center['center_lon']], [center['center_lat']])[0]\n",
    "        })\n",
    "\n",
    "for province, result in dbscan_results.items():\n",
    "    for center in result['cluster_centers']:\n",
    "        all_cluster_centers.append({\n",
    "            'province': province,\n",
    "            'method': 'DBSCAN',\n",
    "            'cluster_id': center['cluster_id'],\n",
    "            'road_count': center['road_count'],\n",
    "            'center_lon': center['center_lon'],\n",
    "            'center_lat': center['center_lat'],\n",
    "            'geometry': gpd.points_from_xy([center['center_lon']], [center['center_lat']])[0]\n",
    "        })\n",
    "\n",
    "# è½¬æ¢ä¸ºGeoDataFrame\n",
    "cluster_centers_gdf = gpd.GeoDataFrame(all_cluster_centers, crs='EPSG:4326')\n",
    "\n",
    "# ä¿å­˜åˆ°æ–‡ä»¶\n",
    "cluster_centers_gdf.to_file(output_filename, layer='cluster_centers', driver=\"GPKG\")\n",
    "\n",
    "print(f\"âœ… èšç±»ä¸­å¿ƒå·²ä¿å­˜åˆ° '{output_filename}' çš„ 'cluster_centers' å›¾å±‚\")\n",
    "print(f\"ğŸ“ˆ æ€»è®¡ä¿å­˜äº† {len(cluster_centers_gdf)} ä¸ªèšç±»ä¸­å¿ƒç‚¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3a0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:46:13.702Z",
     "start_time": "2025-07-26T03:46:11.890943Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "def create_comprehensive_cluster_map(figsize=(20, 16)):\n",
    "    \"\"\"\n",
    "    ç»¼åˆå±•ç¤ºè¡Œæ”¿åŒºè¾¹ç•Œã€é“è·¯åº•å›¾å’Œèšç±»ä¸­å¿ƒ\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "    # 1. ç»˜åˆ¶è¡Œæ”¿åŒºè¾¹ç•Œ\n",
    "    aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "    aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0)\n",
    "\n",
    "    # 2. ç»˜åˆ¶æ‰€æœ‰é“è·¯ï¼ˆåº•å±‚ï¼‰\n",
    "    dissolved_roads_in_aoi.plot(ax=ax, color='lightgray', linewidth=0.5, alpha=0.5, zorder=2)\n",
    "\n",
    "    # 3. ç»˜åˆ¶èšç±»ä¸­å¿ƒ\n",
    "    unique_provinces = list(set(kmeans_results.keys()) | set(dbscan_results.keys()))\n",
    "    colors = cm.tab20(np.linspace(0, 1, len(unique_provinces)))\n",
    "    province_colors = dict(zip(unique_provinces, colors))\n",
    "\n",
    "    for province, result in kmeans_results.items():\n",
    "        color = province_colors[province]\n",
    "        for center in result['cluster_centers']:\n",
    "            ax.scatter(center['center_lon'], center['center_lat'],\n",
    "                       c=[color], s=center['road_count'] * 10 + 50,  # æ ¹æ®é“è·¯æ•°é‡è°ƒæ•´å¤§å°\n",
    "                       marker='o', alpha=0.8, edgecolor='white', linewidth=2,\n",
    "                       label=f\"{province} (KMeans)\" if center['cluster_id']==0 else \"\",\n",
    "                       zorder=4)\n",
    "\n",
    "    # å›¾ä¾‹å’Œæ ·å¼\n",
    "    ax.set_title(\"ä¸Šæµ·åœ°åè·¯ç½‘èšç±»åˆ†æ\\nå„çœä»½é“è·¯ç©ºé—´åˆ†å¸ƒæ¨¡å¼\", fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('ç»åº¦'); ax.set_ylabel('çº¬åº¦')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, frameon=True)\n",
    "    ax.text(0.02, 0.98,\n",
    "            \"â— åœ†å½¢: KMeans ä¸­å¿ƒ\\n\",\n",
    "            transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.9))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"ğŸ—ºï¸ ç”Ÿæˆå¸¦è¡Œæ”¿åŒºåˆ’ã€é“è·¯å’Œèšç±»ä¸­å¿ƒçš„ç»¼åˆåœ°å›¾...\")\n",
    "create_comprehensive_cluster_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad925890",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gdf.drop(columns=['centroid', 'lon', 'lat']).to_file(output_filename, layer=\"matched_roads\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥æ‰¾åœ°å\n",
    "final_gdf.query(\"name == 'å››å·åŒ—è·¯'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ef46e01251cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:32:00.525444Z",
     "start_time": "2025-07-26T03:32:00.523301Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO å¯ä»¥æ ¹æ®é“è·¯çº¿çš„é•¿åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7594e19cfbcf7a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:32:00.575043Z",
     "start_time": "2025-07-26T03:32:00.573255Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4.8 åŒºåŸŸåŒ–åˆ†æ - ä»ç‚¹é›†åˆ°åŒºåŸŸå¤šè¾¹å½¢\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import ConvexHull\n",
    "import alphashape\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_cluster_regions(province_name, method='both', buffer_distance=0.005):\n",
    "    \"\"\"\n",
    "    ä¸ºæŒ‡å®šçœä»½çš„èšç±»åˆ›å»ºåŒºåŸŸå¤šè¾¹å½¢\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - province_name: çœä»½åç§°\n",
    "    - method: ä½¿ç”¨çš„èšç±»æ–¹æ³• ('kmeans', 'dbscan', 'both')\n",
    "    - buffer_distance: ç¼“å†²åŒºè·ç¦»ï¼ˆç»çº¬åº¦å•ä½ï¼Œçº¦500ç±³â‰ˆ0.005åº¦ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    - åŒ…å«åŒºåŸŸå¤šè¾¹å½¢çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    \n",
    "    regions_data = {\n",
    "        'kmeans_regions': [],\n",
    "        'dbscan_regions': [],\n",
    "        'province': province_name\n",
    "    }\n",
    "    \n",
    "    # å¤„ç†KMeansèšç±»åŒºåŸŸ\n",
    "    if method in ['kmeans', 'both'] and province_name in kmeans_results:\n",
    "        result = kmeans_results[province_name]\n",
    "        roads_data = result['roads_with_clusters']\n",
    "        \n",
    "        for cluster_id in roads_data['cluster'].unique():\n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            points = [(row['lon'], row['lat']) for _, row in cluster_roads.iterrows()]\n",
    "            \n",
    "            region_poly = create_region_polygon(points, buffer_distance)\n",
    "            if region_poly:\n",
    "                regions_data['kmeans_regions'].append({\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'geometry': region_poly,\n",
    "                    'road_count': len(cluster_roads),\n",
    "                    'roads': cluster_roads['name'].tolist(),\n",
    "                    'area_km2': calculate_polygon_area_km2(region_poly)\n",
    "                })\n",
    "    \n",
    "    # å¤„ç†DBSCANèšç±»åŒºåŸŸ\n",
    "    if method in ['dbscan', 'both'] and province_name in dbscan_results:\n",
    "        result = dbscan_results[province_name]\n",
    "        roads_data = result['roads_with_clusters']\n",
    "        \n",
    "        for cluster_id in roads_data['cluster'].unique():\n",
    "            if cluster_id == -1:  # è·³è¿‡å™ªå£°ç‚¹\n",
    "                continue\n",
    "                \n",
    "            cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "            points = [(row['lon'], row['lat']) for _, row in cluster_roads.iterrows()]\n",
    "            \n",
    "            region_poly = create_region_polygon(points, buffer_distance)\n",
    "            if region_poly:\n",
    "                regions_data['dbscan_regions'].append({\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'geometry': region_poly,\n",
    "                    'road_count': len(cluster_roads),\n",
    "                    'roads': cluster_roads['name'].tolist(),\n",
    "                    'area_km2': calculate_polygon_area_km2(region_poly)\n",
    "                })\n",
    "    \n",
    "    return regions_data\n",
    "\n",
    "def create_region_polygon(points, buffer_distance=0.005, method='convex_hull'):\n",
    "    \"\"\"\n",
    "    ä»ç‚¹é›†åˆ›å»ºåŒºåŸŸå¤šè¾¹å½¢\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - points: ç‚¹åæ ‡åˆ—è¡¨ [(lon, lat), ...]\n",
    "    - buffer_distance: ç¼“å†²åŒºè·ç¦»\n",
    "    - method: 'convex_hull', 'alpha_shape', 'buffer_union'\n",
    "    \n",
    "    è¿”å›:\n",
    "    - Shapely Polygonå¯¹è±¡\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(points) < 3:\n",
    "        # ç‚¹æ•°ä¸è¶³ï¼Œåˆ›å»ºç¼“å†²åŒº\n",
    "        if len(points) == 1:\n",
    "            point = Point(points[0])\n",
    "            return point.buffer(buffer_distance)\n",
    "        elif len(points) == 2:\n",
    "            from shapely.geometry import LineString\n",
    "            line = LineString(points)\n",
    "            return line.buffer(buffer_distance)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if method == 'convex_hull':\n",
    "            # æ–¹æ³•1: å‡¸åŒ… + ç¼“å†²åŒºï¼ˆæœ€ç¨³å®šï¼‰\n",
    "            hull = ConvexHull(points)\n",
    "            hull_points = [points[i] for i in hull.vertices]\n",
    "            polygon = Polygon(hull_points)\n",
    "            return polygon.buffer(buffer_distance)\n",
    "            \n",
    "        elif method == 'alpha_shape':\n",
    "            # æ–¹æ³•2: Alpha Shapeï¼ˆæ›´è´´åˆå®é™…å½¢çŠ¶ï¼Œä½†å¯èƒ½ä¸ç¨³å®šï¼‰\n",
    "            try:\n",
    "                alpha_shape = alphashape.alphashape(points, 0.1)\n",
    "                if alpha_shape.geom_type == 'Polygon':\n",
    "                    return alpha_shape.buffer(buffer_distance)\n",
    "                elif alpha_shape.geom_type == 'MultiPolygon':\n",
    "                    # å–æœ€å¤§çš„å¤šè¾¹å½¢\n",
    "                    largest = max(alpha_shape.geoms, key=lambda x: x.area)\n",
    "                    return largest.buffer(buffer_distance)\n",
    "            except:\n",
    "                # Alpha shapeå¤±è´¥ï¼Œå›é€€åˆ°å‡¸åŒ…\n",
    "                hull = ConvexHull(points)\n",
    "                hull_points = [points[i] for i in hull.vertices]\n",
    "                polygon = Polygon(hull_points)\n",
    "                return polygon.buffer(buffer_distance)\n",
    "                \n",
    "        elif method == 'buffer_union':\n",
    "            # æ–¹æ³•3: ç‚¹ç¼“å†²åŒºè”åˆï¼ˆé€‚åˆåˆ†æ•£åˆ†å¸ƒï¼‰\n",
    "            buffered_points = [Point(p).buffer(buffer_distance) for p in points]\n",
    "            union_result = unary_union(buffered_points)\n",
    "            return union_result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"åˆ›å»ºå¤šè¾¹å½¢å¤±è´¥: {e}\")\n",
    "        # å¤±è´¥æ—¶åˆ›å»ºç®€å•ç¼“å†²åŒºè”åˆ\n",
    "        try:\n",
    "            buffered_points = [Point(p).buffer(buffer_distance) for p in points]\n",
    "            return unary_union(buffered_points)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def calculate_polygon_area_km2(polygon):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å¤šè¾¹å½¢é¢ç§¯ï¼ˆå¹³æ–¹å…¬é‡Œï¼‰\n",
    "    æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼è®¡ç®—ï¼Œé€‚ç”¨äºå°èŒƒå›´åŒºåŸŸ\n",
    "    \"\"\"\n",
    "    if polygon is None:\n",
    "        return 0\n",
    "        \n",
    "    # å°†åº¦è½¬æ¢ä¸ºç±³çš„è¿‘ä¼¼ç³»æ•°ï¼ˆåœ¨ä¸Šæµ·çº¬åº¦é™„è¿‘ï¼‰\n",
    "    lat_to_m = 111000  # 1åº¦çº¬åº¦ â‰ˆ 111km\n",
    "    lon_to_m = 91000   # 1åº¦ç»åº¦ â‰ˆ 91kmï¼ˆåœ¨åŒ—çº¬31åº¦é™„è¿‘ï¼‰\n",
    "    \n",
    "    # è·å–è¾¹ç•Œæ¡†\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    \n",
    "    # ç®€å•çš„é¢ç§¯ä¼°ç®—ï¼ˆçŸ©å½¢è¿‘ä¼¼ï¼‰\n",
    "    width_m = (maxx - minx) * lon_to_m\n",
    "    height_m = (maxy - miny) * lat_to_m\n",
    "    \n",
    "    # æ›´ç²¾ç¡®çš„æ–¹æ³•ï¼šä½¿ç”¨Shapelyçš„é¢ç§¯å¹¶è½¬æ¢\n",
    "    area_deg2 = polygon.area\n",
    "    area_m2 = area_deg2 * lat_to_m * lon_to_m\n",
    "    area_km2 = area_m2 / 1000000\n",
    "    \n",
    "    return round(area_km2, 3)\n",
    "\n",
    "print(\"âœ… åŒºåŸŸåŒ–åˆ†æå‡½æ•°å®šä¹‰å®Œæˆ\")\n",
    "\n",
    "# ä¸ºæ‰€æœ‰ç›®æ ‡çœä»½åˆ›å»ºåŒºåŸŸå¤šè¾¹å½¢\n",
    "print(\"\\nğŸ—ºï¸ å¼€å§‹åˆ›å»ºèšç±»åŒºåŸŸå¤šè¾¹å½¢...\")\n",
    "\n",
    "all_regions_data = {}\n",
    "\n",
    "for province in target_provinces:\n",
    "    print(f\"ğŸ” å¤„ç† {province} çš„åŒºåŸŸåŒ–...\")\n",
    "    regions = create_cluster_regions(province, method='both', buffer_distance=0.003)\n",
    "    all_regions_data[province] = regions\n",
    "    \n",
    "    kmeans_count = len(regions['kmeans_regions'])\n",
    "    dbscan_count = len(regions['dbscan_regions'])\n",
    "    print(f\"   âœ… KMeans: {kmeans_count} ä¸ªåŒºåŸŸ, DBSCAN: {dbscan_count} ä¸ªåŒºåŸŸ\")\n",
    "\n",
    "print(\"\\nğŸ‰ åŒºåŸŸåŒ–å¤„ç†å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd0f92878936e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.9 å¯è§†åŒ–èšç±»åŒºåŸŸ\n",
    "def plot_province_cluster_regions(province_name, method='both', figsize=(16, 6), show_plot=True):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–ç‰¹å®šçœä»½çš„èšç±»åŒºåŸŸå¤šè¾¹å½¢\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'both':\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        axes = [ax1, ax2]\n",
    "        methods = ['kmeans', 'dbscan']\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        axes = [ax]\n",
    "        methods = [method]\n",
    "\n",
    "    # è·å–åŒºåŸŸæ•°æ®\n",
    "    regions_data = all_regions_data.get(province_name, {})\n",
    "    road_count = province_stats[province_name]\n",
    "    sample_roads = ', '.join(final_gdf[final_gdf['province'] == province_name]['name'].unique()[:5])\n",
    "    if len(final_gdf[final_gdf['province'] == province_name]['name'].unique()) > 5:\n",
    "        sample_roads += \"...\"\n",
    "\n",
    "    for i, current_method in enumerate(methods):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # ç»˜åˆ¶ä¸Šæµ·è¡Œæ”¿åŒºåˆ’åº•å›¾\n",
    "        aoi_gdf = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"EPSG:4326\")\n",
    "        aoi_gdf.boundary.plot(ax=ax, color='black', linewidth=1.5, alpha=0.8, zorder=0)\n",
    "        \n",
    "        # ç»˜åˆ¶æ‰€æœ‰é“è·¯ï¼ˆèƒŒæ™¯ï¼‰\n",
    "        roads_in_aoi_gdf.plot(ax=ax, color='lightgray', linewidth=0.3, alpha=0.4, zorder=1)\n",
    "\n",
    "        if current_method == 'kmeans':\n",
    "            regions = regions_data.get('kmeans_regions', [])\n",
    "            title = f\"{province_name} - KMeans èšç±»åŒºåŸŸ ({len(regions)} ä¸ªåŒºåŸŸ)\\n ç¤ºä¾‹: {sample_roads}\"\n",
    "        else:\n",
    "            regions = regions_data.get('dbscan_regions', [])\n",
    "            title = f\"{province_name} - DBSCAN èšç±»åŒºåŸŸ ({len(regions)} ä¸ªåŒºåŸŸ)\\n ç¤ºä¾‹: {sample_roads}\"\n",
    "\n",
    "        if not regions:\n",
    "            ax.text(0.5, 0.5, f\"æ—  {current_method.upper()} èšç±»åŒºåŸŸ\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(title)\n",
    "            continue\n",
    "        \n",
    "        # ç»˜åˆ¶èšç±»åŒºåŸŸå¤šè¾¹å½¢\n",
    "        colors = cm.tab10(np.linspace(0, 1, len(regions)))\n",
    "        \n",
    "        for j, region in enumerate(regions):\n",
    "            # åˆ›å»ºGeoDataFrameæ¥ç»˜åˆ¶å¤šè¾¹å½¢\n",
    "            region_gdf = gpd.GeoDataFrame([region], crs='EPSG:4326')\n",
    "            \n",
    "            # ç»˜åˆ¶å¤šè¾¹å½¢åŒºåŸŸï¼ˆåŠé€æ˜å¡«å……ï¼‰\n",
    "            region_gdf.plot(ax=ax, \n",
    "                           color=colors[j], \n",
    "                           alpha=0.3, \n",
    "                           edgecolor=colors[j], \n",
    "                           linewidth=2,\n",
    "                           label=f\"èšç±» {region['cluster_id']} ({region['road_count']}æ¡è·¯)\",\n",
    "                           zorder=3)\n",
    "            \n",
    "            # åœ¨åŒºåŸŸä¸­å¿ƒæ·»åŠ æ ‡æ³¨\n",
    "            centroid = region['geometry'].centroid\n",
    "            ax.annotate(f\"C{region['cluster_id']}\\n{region['road_count']}æ¡\\n{region['area_km2']}kmÂ²\",\n",
    "                       (centroid.x, centroid.y),\n",
    "                       ha='center', va='center',\n",
    "                       fontsize=8, weight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                               facecolor='white', \n",
    "                               alpha=0.8,\n",
    "                               edgecolor=colors[j]),\n",
    "                       zorder=5)\n",
    "        \n",
    "        # ç»˜åˆ¶é“è·¯ç‚¹\n",
    "        if current_method == 'kmeans' and province_name in kmeans_results:\n",
    "            roads_data = kmeans_results[province_name]['roads_with_clusters']\n",
    "        elif current_method == 'dbscan' and province_name in dbscan_results:\n",
    "            roads_data = dbscan_results[province_name]['roads_with_clusters']\n",
    "        else:\n",
    "            roads_data = None\n",
    "            \n",
    "        if roads_data is not None:\n",
    "            for cluster_id in roads_data['cluster'].unique():\n",
    "                if cluster_id == -1:  # è·³è¿‡DBSCANå™ªå£°ç‚¹\n",
    "                    continue\n",
    "                cluster_roads = roads_data[roads_data['cluster'] == cluster_id]\n",
    "                color_idx = cluster_id if cluster_id < len(colors) else cluster_id % len(colors)\n",
    "                ax.scatter(cluster_roads['lon'], cluster_roads['lat'], \n",
    "                          c=[colors[color_idx]], s=15, alpha=0.8, \n",
    "                          edgecolor='white', linewidth=0.5,\n",
    "                          zorder=4)\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('ç»åº¦')\n",
    "        ax.set_ylabel('çº¬åº¦')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    return fig\n",
    "\n",
    "# å¯è§†åŒ–å‡ ä¸ªä»£è¡¨æ€§çœä»½çš„åŒºåŸŸ\n",
    "representative_provinces = ['æ±Ÿè‹çœ', 'æµ™æ±Ÿçœ', 'å±±ä¸œçœ', 'å®‰å¾½çœ']\n",
    "\n",
    "for province in representative_provinces:\n",
    "    if province in target_provinces:\n",
    "        print(f\"\\nğŸ“Š {province} èšç±»åŒºåŸŸå¯è§†åŒ–:\")\n",
    "        plot_province_cluster_regions(province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536b5abacfaf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.10 ä¿å­˜åŒºåŸŸåŒ–ç»“æœ\n",
    "def save_cluster_regions():\n",
    "    \"\"\"\n",
    "    ä¿å­˜æ‰€æœ‰èšç±»åŒºåŸŸä¸ºåœ°ç†æ•°æ®æ–‡ä»¶\n",
    "    \"\"\"\n",
    "    \n",
    "    # å‡†å¤‡KMeansåŒºåŸŸæ•°æ®\n",
    "    kmeans_regions_list = []\n",
    "    for province, regions_data in all_regions_data.items():\n",
    "        for region in regions_data['kmeans_regions']:\n",
    "            kmeans_regions_list.append({\n",
    "                'province': province,\n",
    "                'method': 'KMeans',\n",
    "                'cluster_id': region['cluster_id'],\n",
    "                'road_count': region['road_count'],\n",
    "                'area_km2': region['area_km2'],\n",
    "                'roads_sample': ', '.join(region['roads'][:5]) + ('...' if len(region['roads']) > 5 else ''),\n",
    "                'geometry': region['geometry']\n",
    "            })\n",
    "    \n",
    "    # å‡†å¤‡DBSCANåŒºåŸŸæ•°æ®\n",
    "    dbscan_regions_list = []\n",
    "    for province, regions_data in all_regions_data.items():\n",
    "        for region in regions_data['dbscan_regions']:\n",
    "            dbscan_regions_list.append({\n",
    "                'province': province,\n",
    "                'method': 'DBSCAN',\n",
    "                'cluster_id': region['cluster_id'],\n",
    "                'road_count': region['road_count'],\n",
    "                'area_km2': region['area_km2'],\n",
    "                'roads_sample': ', '.join(region['roads'][:5]) + ('...' if len(region['roads']) > 5 else ''),\n",
    "                'geometry': region['geometry']\n",
    "            })\n",
    "    \n",
    "    # ä¿å­˜ä¸ºGeoDataFrame\n",
    "    if kmeans_regions_list:\n",
    "        kmeans_regions_gdf = gpd.GeoDataFrame(kmeans_regions_list, crs='EPSG:4326')\n",
    "        kmeans_regions_gdf.to_file(output_filename, layer='kmeans_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"âœ… KMeansåŒºåŸŸå·²ä¿å­˜: {len(kmeans_regions_gdf)} ä¸ªåŒºåŸŸ\")\n",
    "    \n",
    "    if dbscan_regions_list:\n",
    "        dbscan_regions_gdf = gpd.GeoDataFrame(dbscan_regions_list, crs='EPSG:4326')\n",
    "        dbscan_regions_gdf.to_file(output_filename, layer='dbscan_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"âœ… DBSCANåŒºåŸŸå·²ä¿å­˜: {len(dbscan_regions_gdf)} ä¸ªåŒºåŸŸ\")\n",
    "    \n",
    "    # åˆå¹¶æ‰€æœ‰åŒºåŸŸ\n",
    "    all_regions_list = kmeans_regions_list + dbscan_regions_list\n",
    "    if all_regions_list:\n",
    "        all_regions_gdf = gpd.GeoDataFrame(all_regions_list, crs='EPSG:4326')\n",
    "        all_regions_gdf.to_file(output_filename, layer='all_cluster_regions', driver=\"GPKG\", engine=\"fiona\")\n",
    "        print(f\"âœ… æ‰€æœ‰èšç±»åŒºåŸŸå·²ä¿å­˜: {len(all_regions_gdf)} ä¸ªåŒºåŸŸ\")\n",
    "\n",
    "# æ‰§è¡Œä¿å­˜\n",
    "print(\"\\nğŸ’¾ ä¿å­˜åŒºåŸŸåŒ–ç»“æœ...\")\n",
    "save_cluster_regions()\n",
    "\n",
    "# ç»Ÿè®¡åŒºåŸŸåŒ–ç»“æœ\n",
    "print(\"\\nğŸ“Š åŒºåŸŸåŒ–ç»Ÿè®¡æ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_kmeans_regions = 0\n",
    "total_dbscan_regions = 0\n",
    "total_area_kmeans = 0\n",
    "total_area_dbscan = 0\n",
    "\n",
    "for province, regions_data in all_regions_data.items():\n",
    "    kmeans_count = len(regions_data['kmeans_regions'])\n",
    "    dbscan_count = len(regions_data['dbscan_regions'])\n",
    "    \n",
    "    kmeans_area = sum(r['area_km2'] for r in regions_data['kmeans_regions'])\n",
    "    dbscan_area = sum(r['area_km2'] for r in regions_data['dbscan_regions'])\n",
    "    \n",
    "    total_kmeans_regions += kmeans_count\n",
    "    total_dbscan_regions += dbscan_count\n",
    "    total_area_kmeans += kmeans_area\n",
    "    total_area_dbscan += dbscan_area\n",
    "    \n",
    "    print(f\"{province:8s}: KMeans {kmeans_count:2d}åŒºåŸŸ({kmeans_area:5.1f}kmÂ²) | DBSCAN {dbscan_count:2d}åŒºåŸŸ({dbscan_area:5.1f}kmÂ²)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"æ€»è®¡: KMeans {total_kmeans_regions}åŒºåŸŸ({total_area_kmeans:.1f}kmÂ²) | DBSCAN {total_dbscan_regions}åŒºåŸŸ({total_area_dbscan:.1f}kmÂ²)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ac71fe7902c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.11 ä¿å­˜åŒºåŸŸå¯è§†åŒ–å›¾ç‰‡\n",
    "print(\"\\nğŸ“Š ä¿å­˜æ‰€æœ‰çœä»½çš„åŒºåŸŸå¯è§†åŒ–å›¾...\")\n",
    "\n",
    "# åˆ›å»ºåŒºåŸŸå¯è§†åŒ–æ–‡ä»¶å¤¹\n",
    "regions_output_folder = 'image/province_cluster_regions_visualization'\n",
    "Path(regions_output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for province in target_provinces:\n",
    "    if province in all_regions_data:\n",
    "        print(f\"ğŸ“Š æ­£åœ¨ä¿å­˜ {province} çš„èšç±»åŒºåŸŸå›¾...\")\n",
    "        \n",
    "        # åˆ›å»ºå›¾å½¢\n",
    "        fig = plot_province_cluster_regions(province, method='both', figsize=(16, 6), show_plot=False)\n",
    "        \n",
    "        \n",
    "        # ä¿å­˜å›¾å½¢\n",
    "        plt.savefig(Path(regions_output_folder) / f\"{province}_cluster_regions.png\", \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=300,\n",
    "                    facecolor='white')\n",
    "        \n",
    "        # å…³é—­å›¾å½¢é‡Šæ”¾å†…å­˜\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"âœ… æ‰€æœ‰èšç±»åŒºåŸŸå¯è§†åŒ–å›¾å·²ä¿å­˜åˆ° '{regions_output_folder}' æ–‡ä»¶å¤¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48875286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shanghai-road-clustering-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
